
Начало положено. Загрузка 10 млн. триплетов, кодированных целыми числами выполняется 1.6 сек.

Индексирование по субъекту выполняется за 25 сек. По субъекту и предикату - за 17.9 сек. (!) Я уже сталкивался
с тем, что ссылочный массив сортируется быстрее, похоже из-за этого. Надо проверить, что сортировка правильная.

Времена для теста с 10 млн. триплетов: загрузка 2.7 сек., сортировка 18 сек., бинарный поиск - 1 мс.
для теста в 100 млн. триплетов: загрузка 30.7 сек., сортировка 2092 сек. (9 слияний), бинарный поиск - 1 мс.
При запуске бинарного поиска без загузка, получается 3 мс.

Слияния начинаются с 12.5 млн. Это логично - если умножить на 8, получится 100 млн. байтов. Кажется именно такой
размер буфера сейчас установлен. Надо попробовать с буфером в 400 млн.

Прогон 100 млн. (условных) триплетов с буфером 400 М, дал результаты:
загрузка 27 сек., сортировка 1273 сек. (три слияния)
Кстати, база данных состоит из ячейки объектных триплетов 1.11 Гб. и ячейки индекса 762 Мб.  

Прогноз на 1 млрд. загрузка 300 сек., сортировка 20 тыс. сек. Где-нибудь часов 6. Что-то многовато. Но в реальных 
триплетах, объектных своств около половины, так что можите и меньше, но добавится работа с полями данных. 

Эта часть неплохо сочетается с выделением идентификаторов, но время в целом можно оценить как 10 часов. Это много.
Но дело в том, что похоже лимитирующим фактором является скорость доступа к диску. Я вижу, что по ходу ввода, 
процессор занят процентов на 15. Если использовать этот резерв, напр. за счет RAID'а, результаты без распараллеливания
могут быть порядка одного часа. 

Как можно ускорить процесс загрузки? Естественно, возможности надо искать там, где времена определяющие процесс. То есть,
процесс сортировки. Похоже совсем немного можно выиграть на использовании большой оперативной памяти. Надо еще посмотреть 
на вариации на тему Array.Sort(). Можно попробовать из двух целых сделать одно двойное, т.е. отказаться от использования
класса, группирующего сортируемые значения. Правда, в некоторых эксперимента получилось, что ссылочные типы сортируются
быстрее. Раза в 2 может оказаться существенным. 

Более принципиальной возможностью является распараллеливание. Однако, это совсем не очевидный путь. Возможно, он сулит
что-нибудь в маркетинговом плане если провести эксперимент на суперкомпьютере или суперкластере, обладающих скоростью
межпроцессорного обмена сопоставимой со скоростью обмена с диском. Тогда, например, делим миллиард триплетов (уже в
кодированном виде) на N машин кластера. Это значит, надо передать порядка 100 Гб. по сети. Сколько такая передача может 
занять времени? С диска на диск пишется 10 минут. Лучше двигаться в сторону RAID. К тому же если взять кодирование и 
индексы, все слишком тесно переплетено, чтобы легко работать над отдельными кусками. Придется сортировку выполнять
прямо на значениях, а не на индексах. В частности, это означает, что придется продублировать таблицу объектных свойств
для того, чтобы с ней работать. Но еще одна возможность - не завершать сортировку. Например, получил процесс часть
таблицы, создал нужные индексы. Граф готов. Если нужно множество предикатов, удовлетворяющих какому-то критерию, 
делается запрос ко всем машинам кластера и собираются результаты. Если не включать в подстчет затрат время на деление 
массива на части, то задача полностью распараллеливается. Так что 100 миллиардов триплетов можно обрабатывать на 100
машинах кластера. Ну и триллион тоже... Подозреваю, что за подобной возможностью ничего кроме рекламы не будет...
Ну и наконец, моя старая задумка: разделить граф на части так, чтобы части были приблизительно одинакового размера и
чтобы число внешних для частей объектов было минимально. Но до такого эксперимента еще надо "дорасти".




 
 

 
  