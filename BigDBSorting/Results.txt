Результаты проверки индексирования строкового столбца

1 млн. - Загрузка 2.9 сек. Индексирование 9.4 сек.
10 млн. - загрузка 40.9 сек. Индексирование 1227 сек. ???

Поиск 1000 случайных значений - 1 сек. Повторно - 370 мс.
После перезагрузки - 363 мс.

Сделал детерминированную псевдослучайную последовательность.
Результаты объяснимы. Для 1 млн. значений, 1000 поисков занимает 459 мс.
Еще раз: 400 мс.

Проведу снова эксперименты с 10 млн.

На рабочем компьютере

загрузка 6.3 сек., индексирование 60.2 сек., 1000 поисков 237 мс.

Попробую 100 млн. - не получилось в 32-разрядной моде, не получилось и 20 млн.

Снова 10 млн. 5.7 сек - загрузка, 62.3 - индексирование, 245 мс. 1000 поисков.
При запуске без загрузки получилось 190 мс. на 1000 поисков.

100 млн. идентификаторов не удалось обработать. Причина, возможно в исчерпании оперативной памяти.

40 млн. Загрузка - 22 сек. Индексирование - 373 сек. 1000 поисков - 108 сек. (???).
Повторный пропуск поисков без загрузки - 190 мс. (!!!). 
Предположение - ранее поиск выполнялся на фоне освобождения памяти (около 8 Гб).

База данных: scell - 2245 Gb., icell - 312 Mb.


40 млн. Загрузка - 23 сек. Индексирование - 574 сек. 1000 поисков - 193 мс.

После полной перезагрузки компьютера, выполнение бинарных поисков стало значительно хуже.
Точне пока не засек, но 1000 запросов выполняется секунд 200-300. То есть, замедление примерно в 
1000 раз. Похоже, надо разогревать. Попробую.

После разогрева массива индекса, который длился более 20 сек. 1000 поисков выполнялось за 201 сек. 
Полный разогрев длится 53 сек., 1000 поисков выполняется 190 мс. 
Повторно, разогрев выполняется за 9.37 сек.

======== 10 млн. идентификаторов, кабинетный компьютер =========
Загрузка 7 сек., индексирование 77 сек.,   

==== Работа на SSD 
Загрузка 5.4 сек., индексирование 77.6 сек.
разогрев 1 - 520 мс., разогрев 2 - 4 сек.

Без разогрева (!)
первая 1000 - 3300 мс.
вторые 2000 - 2580 мс.
третьи 2000 - 360 мс. - вышла на штатный режим.

=========== Новые эксперименты ===========
Делаю попытку испытать работу системы в условиях, когда оперативной памяти может не хватать на все данные. 
Для этого ...

100 млн. длинных (более 100 символов) строк (идентификаторов)
Загрузка 245 сек., выполнение 100 тыс. выборок - чуть больше 1 сек. (~1090 мс.)
База данных: строки - 11 Гб. индексы - 781 Мб.

SSD
Загрузка 84 сек., выполнение 100 тыс. выборок - чуть больше 1 сек. (~1055 мс.)

На 1 млрд. данных, ситуация существенно хуже. 
HDD
Загрузка 4073 сек. Выполнение 100 тыс выборок - 2300 сек. !!!
Правда процесс очень "скромно" себя "ведет" - занимает меньше 8 Мб. ОЗУ. Кажется, он застрял после 4-й порции.

SSD
Загрука 750 сек. Выполнение 100 тыс выборок - 41 сек. Почти в 6 раз быстрее!!! второе выполнение 35 сек. третье - 33 сек.
и так со снижением. Последний, 10-й просчет прошел за 28.5 сек.
Второй пропуск теста (без загрузки) дал приближительно те же результаты. 
База данных: строки 114 Гб, индексы - 7.8 Гб.

Попробовал разогрев для этих данных (на SSD). Сканирование произведено за 44.4 сек и 661 сек.
Но далее все по-прежнему. Пакеты по 100 тыс. выборок выполняются за 37, 36, 34.6, ... сек.

Теперь надо проверить нужен ли для SSD разогрев для данных, на которых пулчается высокая скорость. 

100 млн. 
Снова згрузил данные на SSD. Все также, только загрузка длилась 73 сек.
Без загрузки. Разогрев 4.9 + 69 сек. Потом даже быстрее 925-949 мс.
Без загрузки и без разогрева. 33.5, 25.3, 21.2, ... 13.7 сек. 

Без разогрева жить нельзя!!!

 
 
====== 20140528 =======
Эксперимент: Проверка таблицы с индексами

На домашнем компьютере, 1 млн. записей: 
загрузка 1.8 сек., id_index 6.6, dt_index 14.9, nm_index 14.2 сек.

10 млн. записей
загрузка 22.5 сек., id_index 122, dt_index 360, nm_index 248 сек.
еще раз
загрузка 56.8 сек., id_index 102, dt_index 461, nm_index 214 сек.
Объем базы данных: table 366 Мб., индексы - по 78 Мб.

Была несущественная ошибка. Снова:
загрузка 68.7 сек., id_index 124, dt_index 156, nm_index 279 сек.

Как-то медленно выполняется бинарный поиск. Одиночное значение вычисляется за
более чем 600 мс. Но помнится, всегда первый поиск был медленный.

Поиск первого диапазона (457 решений) 489 мс.
Далее, поиск 10 совпадений 49 мс.

-- На рабочем компьютере, 10 млн. записей
загрузка 7.9 сек., id_index 21, dt_index 21, nm_index 69 сек.
первая выборка (457 решений) 308 мс. 
100 следующих - 17 мс. (ВСЕГО!!!)

При запуске без загрузки 327 мс. и 17 мс.
  
====== 20140615 ======
Я вернулся к некоторым предыдущим экспериментам. В частности, меня заинтересовало можно ли "отобрать"
память в Виртуозо. Сйть экспермента в следующем: 
1) Я развернул 100-миллионный тест в Виртуозо. У меня есть некторый тест, на основе 2-го берлинского.
Выполняя его после развертывания, я получил 19 QpS для первых 500 выполнений (с разными константами)
и 37 QpS для второго. Некоторая "предельная" производительность получается при повторном запуске, это
150-170 QpS. 
2) Вторым этапом я произвел загрузку 100 млн. записей средствами программы проверки работы с данными, 
существенно превышающими размер оперативной памяти. 
3) Теперь опчти вся оперативная память машины захватывается при сканировании массивов 762 Мб и 11 Гб,
которые получились. Пусле этого, доступ к случайно выбираемым записям производится черезвычайно медленно.
первая группа из 10 тыс зоступао выполнялась 1242 сек. Всего 8 запросов в сек.!!! НА следующий 10 тыс. 
запросов скорость удвоилась. Потом еще раз удвоилась и еще. Вышла на 100 сек. Уже лучше, но это всего
100 запросов в сек...
4) Теперь выполняю тест через Виртуозо. На первых 500 выполнений, получилось 38.5 QpS, на вторых (это
другие данные!) - 51 QpS. После перезапуска сервера Виртуозо, времена получились 50 и 150 QpS.

В общем, есть над чем подумать...

====== 20140617 ======
Появилась новая идея - посмотреть на производительность MemoryMappedFiles.
Первое - заведу что-то очень простое, напр. последовательность целых чисел большой длины.
Меня интересует Random-доступ к этой последовательности. Квантом является целое. 
Сначала промерю произвоидтельность доступов для Поляровской ячейки свободного формата. 
Потом, для файла прямого доступа. И потом - изучу что даст использование MemoryMappedFiles.

Первый этап (естественно) не дал неожиданностей. Получается 200 тыс доступов в сек. (464 мс. на 100 тыс.)
Увеличил количество чисел в 10 раз - до 1 млрд. Загрузка выполнялась 53 сек. 
100 тыс запросов выполняется по-прежнему 503 мс. 

Теперь поработаю с файлом. 32 байта служебные, потом 8 байтов размер, потом подряд числа...

В общем, неожиданностей опять нет. Из последовательности 100 тыс. целых извлекаются 491 мс. Из файла - 457.

Что-то получилось, но не воодушевляет... Такой же тест на выборку 100 тыс целых выполнялся 575 сек. Надо что-то 
еще почитать...
Улучшить пока не удалось. Так по-прежнему 575 сек.






 


 
 

 


