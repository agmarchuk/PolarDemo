
            // 1000000 - 13 сек. - 8.3 сек. (транзакции и 200 записей буфер)
            // 1000 - 15 мс.
            // 10000 - 100 мс.
            // 100000 - 810 мс.
            // 1000000 - 8 сек.
            // 10000000 - 159 сек.
            // 20000000 - 217 сек.
            // 40000000 - 267 сек.
            // 100000000 - 1678 сек.
            // PolarDB:
            // 1000000 - 187 мс.
            // 10000000 - 1.4 сек.
            // 100000000 - 12.7 сек.
            // 1000000000 - 135-145 сек.
            // Сортировка:
            // 10000000: 16 сек. (14 без слияния)
            // 100000000: 221 сек. Файл - 390 Мб.
            // 1000000000: 4440 сек. Файл - 3900 Мб. 

Эксперименты 20131006 ("средний" компьютер, ОС-32 разряда, ОЗУ - 4 Мб.)
=======================================================================
BigSQL
1000000 - загрузка 43 сек. в режиме индексации первый поиск - 2.2 сек. второй поиск - 1 мс.
повторый запуск с изменением (randcol=9703) - поиски не дали результатов (???). Зато загрузка длилаь 23 сек.
Третий запуск - тот же эффект. Может случайно, нет значений в диапазоне? Проверю.
Действительно, похоже так. Результаты по поискам аналогичны (2 мс. - второй поиск). Размер файла БД - 102 Мб,
но это может накопилось с предыдущих раз.

10000000 - (10 млн.) - загрузка без индексации - 171 сек. Но индексации - "сломалась" по таймауту. Пропробую починить.
Индексация проходила 67 сек. Первый поиск - 47 мс., второй - 3 мс. Почему-то не был найден заданный результат. 
Неужели Random не повторяет последовательность? Файл базы данных 329 мб.
При прогоне только теста, получилось 3 сек. и 27 мс. 

Еще один раз. Загрузка проходила 163 сек. SQL-сервером захватывалось более 380 Мб. ОЗУ. Лог - более 3 Гб.
Индексация проводилась 36 сек. После индексации, первый поиск - 4 мс., второй - 3 мс. Не найдено значение
777777777 (9 семерок), которое я пишу в конце процесса. Непонятно... Следующий запуск без индексации дал
времена 4.3 сек. и 17 мс., семерки опять не найдены. Понял, почему не найдены - яих не записал. Исправил.
Пока тестировал, SQL-сервер захватил помять в 718 Мб. Схожу погуляю, потом посмотрю сколько памяти освободится
и какая будет производительность. Погулял, SQL-сервер освободил память. Прогон дал результаты: первый поиск 
- 2.9 сек., второй - 17 мс. Третий - 2 мс. 

Теперь попробую на рабочем компьютере провести тест с 100 млн. записей.

Эксперименты на рабочем компьютере (довольно скоростной ЦПУ, ОС-64, 16 Гб. ОЗУ)
===============================================================================
BigSQL:
10 млн. 
Загрузка - 100 сек., Файл базы данных - 136 Мб. (лог 3.2 Гб.). Построение индекса - 15 сек. Первый поиск - 4 мс.,
Второй поиск - 2 мс. Третий поиск - 1 мс. SQL-сервер захвател 2.9 Гб. ОЗУ. Еще раз (без индексирования): 289, 32, 1.
Файл базы данных (после индексирования) - 314 Мб. Теперь запущу тест на 100 млн.

100 млн.
Загрузка - 830 сек. файл БД - 1.27 Гб., лог - 29.7 Гб., захват ОЗУ сервером - 3.789 Гб. Построение индекса - 350 сек.
Итоговый размер файла БД - 3.06 Гб. Времена поиска (при запуске без индексирования) - 1.3 сек., 35 мс., 2 мс. Теперь
миллиард.

1000 млн. - 

BigPolar
1000 млн. - загрузка 67 сек. 1404 сек. сортировка, сканирование - 63 сек. 

19.8 сек., 14 сек., 5.7 сек.

 



 



 

 







 

