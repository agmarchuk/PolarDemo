
            // 1000000 - 13 сек. - 8.3 сек. (транзакции и 200 записей буфер)
            // 1000 - 15 мс.
            // 10000 - 100 мс.
            // 100000 - 810 мс.
            // 1000000 - 8 сек.
            // 10000000 - 159 сек.
            // 20000000 - 217 сек.
            // 40000000 - 267 сек.
            // 100000000 - 1678 сек. (756 с. на быстром компьютере + 304 с. индекс + 8.2 чтение)
            // PolarDB:
            // 1000000 - 187 мс.
            // 10000000 - 1.4 сек.
            // 100000000 - 12.7 сек.
            // 1000000000 - 135-145 сек.
            // Сортировка:
            // 10000000: 16 сек. (14 без слияния)
            // 100000000: 221 сек. Файл - 390 Мб.
            // 1000000000: 4440 сек. Файл - 3900 Мб. 

Эксперименты 20131006 ("средний" компьютер, ОС-32 разряда, ОЗУ - 4 Мб.)
=======================================================================
BigSQL
1000000 - загрузка 43 сек. в режиме индексации первый поиск - 2.2 сек. второй поиск - 1 мс.
повторый запуск с изменением (randcol=9703) - поиски не дали результатов (???). Зато загрузка длилаь 23 сек.
Третий запуск - тот же эффект. Может случайно, нет значений в диапазоне? Проверю.
Действительно, похоже так. Результаты по поискам аналогичны (2 мс. - второй поиск). Размер файла БД - 102 Мб,
но это может накопилось с предыдущих раз.

10000000 - (10 млн.) - загрузка без индексации - 171 сек. Но индексации - "сломалась" по таймауту. Пропробую починить.
Индексация проходила 67 сек. Первый поиск - 47 мс., второй - 3 мс. Почему-то не был найден заданный результат. 
Неужели Random не повторяет последовательность? Файл базы данных 329 мб.
При прогоне только теста, получилось 3 сек. и 27 мс. 

Еще один раз. Загрузка проходила 163 сек. SQL-сервером захватывалось более 380 Мб. ОЗУ. Лог - более 3 Гб.
Индексация проводилась 36 сек. После индексации, первый поиск - 4 мс., второй - 3 мс. Не найдено значение
777777777 (9 семерок), которое я пишу в конце процесса. Непонятно... Следующий запуск без индексации дал
времена 4.3 сек. и 17 мс., семерки опять не найдены. Понял, почему не найдены - яих не записал. Исправил.
Пока тестировал, SQL-сервер захватил помять в 718 Мб. Схожу погуляю, потом посмотрю сколько памяти освободится
и какая будет производительность. Погулял, SQL-сервер освободил память. Прогон дал результаты: первый поиск 
- 2.9 сек., второй - 17 мс. Третий - 2 мс. 

Теперь попробую на рабочем компьютере провести тест с 100 млн. записей.

Эксперименты на рабочем компьютере (довольно скоростной ЦПУ, ОС-64, 16 Гб. ОЗУ)
===============================================================================
BigSQL:
10 млн. 
Загрузка - 100 сек., Файл базы данных - 136 Мб. (лог 3.2 Гб.). Построение индекса - 15 сек. Первый поиск - 4 мс.,
Второй поиск - 2 мс. Третий поиск - 1 мс. SQL-сервер захвател 2.9 Гб. ОЗУ. Еще раз (без индексирования): 289, 32, 1.
Файл базы данных (после индексирования) - 314 Мб. Теперь запущу тест на 100 млн.

100 млн.
Загрузка - 830 сек. файл БД - 1.27 Гб., лог - 29.7 Гб., захват ОЗУ сервером - 3.789 Гб. Построение индекса - 350 сек.
Итоговый размер файла БД - 3.06 Гб. Времена поиска (при запуске без индексирования) - 1.3 сек., 35 мс., 2 мс. Теперь
миллиард.

1000 млн. - 

BigPolar
1000 млн. - загрузка 67 сек. 1404 сек. сортировка, сканирование - 63 сек. 

19.8 сек., 14 сек., 5.7 сек.

BigSQL Эксперимертты в поезде 20131014
1 млн. - загрузка 19 сек. (возможно, частота процессора снижена), индексирование 4.5 сек. поиск 6, 3, 3. сканирование 168 мс.
10 млн. - загрузка 160 сек., индекс 58 сек., поиск 15 мс, 0, 0, сканирование 1.4 сек. 
Отдельно повторенная вторая фаза 3.9 s, 31 ms, 0, 5.2 c.
После полной перезагрузки 11.7 сек., 140 мс., 0, 8.3 сек.
100 млн. - грузила минут 30. лог 30 Гб. 

Еще одна попытка сделать и "оживить" 100 млн.
Загрузка произведена за 1522 сек. 
Новая загрузка 1386 сек. и сканирование 24.8 сек. 
Сканирование при независимом запуске 47.5 сек.
Файл 1.27 Гб., Лог 30.2 Гб.
Захвачено SQL-сервером ОЗУ 1.4 Гб.
Еще один прогон. Сканирование 40.1 сек., индексация 600 сек., поиск 62, 15 мс., еще сканирование 34.6 сек.
Размер файла БД 3.06 Гб.
Запуск с уже сформированным индексом и после перезагрузки: поиск 26 сек., 29 мс. сканирование 43.6 сек.
Захвачено 1.3 Гб. ОЗУ. Видимо, все данные "закешировались".

Тестирование 20131103

Провожу тест на строковые данные. Теперь колонка в таблице типа VARCHAR(10). 
Для 100 тыс. записей:
Время ввода - 7.3 сек.
Индексация - 0.6 сек. 
Поиск - 4 мс.

Для 1 млн.:
30 сек., 8 сек., 4 мс.

Если сначала индексировать, а потом загружать, то
100 тыс. - 4.3 сек., поиск 121 мс. зато сканирование выполняется быстро - 33 мс.
для 1 млн. - 37 сек., поиск 2.3 сек., сканирование 297 мс.
для 1 млн. - 30 сек., поиск 1.8 сек., повторный поиск 0 мс.,  сканирование 312 мс.

Вернул работу с целыми. Теперь СНОВА колонка целочисленная
1 млн. - 25 сек., поиск 1.5 сек., сканирование 187 мс.
27, 1.6, 189

Вернул порядок: загрузка - индексирование
1 млн. - 12 сек., 1.9 сек., .., 185 мс.
1 млн. - 12 сек., 1.9 сек., 2 мс., 184 мс.

Тестирование BigPolar (рабочий компьютер)

100 млн. записей:
Загрузка 6 сек.
Индексирование 70 сек.
Сканирование 6.7 сек.
Бинарный поиск 1 мс.
10 бинарных поисков 1 мс.

1 млрд. записей:
Максимальное использование ОЗУ 37 Мб. Объем базы данных (естественно) 3.9 Гб.
Загрузка 60 сек.
Индексирование 812 сек.
Сканирование 66 сек.
Бинарный поиск 1  мс.
10 бинарных поисков 1 мс.
 
Без загрузки и сканирования: 9 мс., 0 мс., 1 мс. (10 поисков)
После перезагрузки компьютера: 197 мс., 128 мс. 705 мс.
Повторный запуск: 10 мс., 0 мс., 0 мс., Найденные значения выведены верные.

Тестирование BigSQL (Петин сервер, Linux, MySQL)
100 млн. записей:
загрузка 275 сек.
индексирование 299 сек.
Всего: 574 сек. (в 8 раз хуже)
Выборка единичных записей ~0 (в пределах ошибки измерения)

Для новоого варианта теста ============== BigBDSorting ===============
Кабинетный компьютер
67 млн. записей (больше без разбивки не сортирует)
загрузка 3.9 сек.
сортировка 13.5 сек.
сканирование 4.4. сек.

Домашний компьютер - 32 р., 2 Гб. ОЗУ:
Загрузка
67 млн. записей
После разгона первые 10 - 5.9 мс., вторые 10 - 2.1 мс.
Полный прогон:
загрузка 12 сек., сортировка 55 сек., первые 10 - 159 мс., вторые 10 - 417 мс.
Повторно: 6 мс, 2.1 мс.

После перезагрузки компьютера
263 мс., 330 мс.
Повторно: 6.3 мс, 2.4 мс.

На бинарном поиске, использующим функцию уровня
6.1, 2.04
После перезагрузки компьютера
6.1, 2.3 - странная перезагрузка...

Надо отказываться от оптимизаций в этом направлении. 

Испытание новых средств сортировки по ключу
===========================================
Домашний компьютер
67 млн. - Загрузка 8.7 сек., индексирование (старый метод) 144 сек., Test5 4 мс., повторно 1.6 мс.

Для сортировки по ключу, что-то не получается...
Если нет слияния, загрузка 4.2 сек., индексация 14 сек. 4.2 мс., 1.7 мс.

Для базовой сортировки по отношению, цифры следующие:
загрузка 3.7 сек., индексация 60 сек., 4.5, 1.7 мс.
При уменьшении размера буфера, при одном слиянии, индексация поизводилась 51 (!) сек. 
При следующем уменьшении в 2 раза, индексация выполнилась за 47 (!!) сек. Парадокс...

Подведу промежуточный итог: 
Без слияния индексация по ключу производится в 4 раза быстрее, со слиянием - недопустимо медленно. 
Надо оптимизировать. 

Три слияния при сортировке по ключу, увеличили время до 484 сек., т.е. в более, чем в 30 раз!!!
Надо разбираться.

Две сортировки выполнились за 11 сек. Логично...
Если сливаемые массивы содержать упорядоченные группы значений, то слияние производится существенно быстрее
- за 72.6 сек. т.е. в 6 (!) раз быстрее. Но это не решает проблему. Видимо надо сделать слияние с использованием
буфера, как при другом слиянии.

Я добился того, что слияние производилось за 2.5 сек. Однако, стоило добавить в начала сортируемого массива
одно (!) большое число, как время сразу стало 150 сек. Вполне объяснимо. Попробую добавить вторую временную ячейку.

Ура! Все получилось. Индекс строится за 22 сек. Попробую уменьшить размер буфера. 
При уменьшении размера буфера в 2 раза получилось 65.6 сек. Это не очень хорошо... Надо над этим работать. 

Что-то странное выявилось. Второй массив сливается 35-43 сек. Это более чем в 7 раз дольше, чем первый 5.4 сек
и в 4 раза дольше, чем общее слияние 10.8 сек. Попробую еще уменьшить размер буфера.

Да, странность воспроизводится. Есть случаи, когда 7.5 млн. чисел сливаются 2.66 сек., а есть, когда 19.2 сек. 
Это в 7.2 раза дольше! Посмотрю код...

Нашел и исправил ошибку. Теперь при 7 слияниях врея слияний - 44 сек. за вычетом времени на сортировки, наверное,
это 11 сек. Получается 33 сек. Причем время растет линейно относительно размера сливаемых массивов. Надо бы время
на слияние уменьшить. Можно было не слиьно беспокоиться относительно размера буфера. НАчинаю увеличивать размер
буфера. При удвоении, суммарное время сортировки получилось 33 сек. При одном слиянии, получилось 23.6 сек. на
индексацию. При отстутствии слияний, время индексации 13.5 сек. 

Теперь чтобы понять полезность оптимизации слияния, проведу эксперимент с другой сортировкой, для которой слияние
вроде получается лучше. Результат оптимистичен. Слияние получилось за 5.7 сек., вся индексация заняла 54 сек. Раза
в 2 лучше.

Рабочий компьютер
Сортировка отношением:
Загрузка 1.8 сек., Индексирование 24.6 сек, в том числе 2.5 сек. - слияние, тесты: 2.9 мс., 0.7 мс.
Сортировка ключами:
Загрузка 1.7 сек., Индексирование 11.3 (4.8) сек., 1.88, 0.47 мс.
При следующем прогоне, индексирование производилось 7.2 сек. (слияния не было).

1 МИЛЛИАРД чисел.
Загрузка 59 сек. (файл 3.72 Гб.), Куски для слияния - 125 млн. чисел. Слияние происходит за 19 сек., Используется 1.2 Гб. ОЗУ
Индексирование 828 сек. тесты: 2.1 мс., 0.9 мс.
повторный пропуск тестов: 3.1, 0.8 мс.
При увеличении буферной зоны в 4 раза: - не увеличивается, выыдает OutOfMemoryException. Предел 400 млн. байт.
НАДО улучшать слияние!

Из 839 сек. индексации, слияние занало 633 сек.!

Кажется, заработало!.. Сейчас идет обработка миллиарда чисел. Получилось 411 сек. на индексацию. Таким образом, слияния заняли лишь 
половину времени. Похоже, что очень неплохо. Ускорил слияние в 3 раза!
Но есть некоторые странности. Время, которое тратилось на слияние было на 11 этапах вполне предсказуемым. 125 М - 4 сек., 250 М - 8 сек.,
500 М - 16 сек., но потом оно вдруг удвоилось: 125 М - 8.4 сек., 250 М - 16 сек., 500 М - 32 сек., 1000 М - 79 сек. Думаю, дело не в
свопинге. Может дефрагментация? Попробую поменять порядок вычислений.

Кстати, программа по максимуму захватывает 1248 Мб ОЗУ.
Порядок поменял, но результаты оказались очень похожими, просто отклонения переместились в другие места. Теперь индексирование заняло 404 сек.

Можно сказать, облом... На случайных данных индексирование выполнялось 900 сек. Правда собственно слияние получается 303 сек. Это всего треть.
 
 


 




   




 



 



 



 

 







 

