
20140703 12:00
Снова начинаю получать результаты. Пока скорость формирования древовидной структуры не очень хорошая.
Да и размер довольно большой. 
Время построения дерева 93 сек. (кажется, раньше быстрее было, раза в два...) До этого - секунд 15.
Объем полученной ячейки  121 мб.

Сразу внесу изменения. Выделю литералы отдельным массивом. 

Частично внес. Получил частичные результаты. Слияние пока не выполняется, но подсчет количества записей 
уже осуществляется. Время - 8 сек. Как-то подозрительно долго...

Забавно, но лучше читаль подряд, даже если это немного дольше. Тепереь вычисление количества записи занимает 821 мс.
Разница в коде:
DiapasonScanner<int> i_fields = new DiapasonScanner<int>(dtriples, ent => (int)((object[])ent.Get())[0]);
//DiapasonScanner<int> i_fields = new DiapasonScanner<int>(dtriples, ent => (int)ent.Field(0).Get()); // в 10 (!) раз медленнее
 
Теперь, наверное в силу особенностей нового варианта дерева, его сборка выполнялась 18.5 сек.
Само дерево теперь ячейка literals и фиксированная ячейка tree_fix
их объемы: 49 Мб и 24.5 Мб.
Есть основание полагать, что на хорошей машине миллиард триплетов будет обрабатываться!..

Произведу еще оптимизацию сканера, как в прошлый раз.

25 738 052 байт

Сборка выполнялась 10.4 сек. Некоторый выигрыш есть.

24,5 МБ (25 738 052 байт) 
24,5 МБ (25 738 052 байт)
При повторном выполнении, сборка дерева выполнялась 6.4 сек.
Общее время на загрузку 1 млн. триплетов - около 17 сек. НА ДОМАШНЕМ КОМПЬЮТЕРЕ
База данных в свободном формате - 19.3 Мб., но не хватает "широкой" таблицы...

20140704 06:31
Сделал первую проверку. Совпало около 1 тыс. выполнений ChkSubjPredObj(int subj, int pred, int obj)
Правда это выполнялось 8.8 сек. Повторно, это выполнилось за 185 мс.

spO выполнилась за 10.9 сек. Повторно - 706 мс. 
Spo выполнялась 72 мс. Это для 250 раз. 

При наличии словаря, spO выполняются 144 мс. 
Spo - 32 мс.
spo - 42 мс.

spO наиболее "трудозатратная", легче заметить закономерность. Если для spO
код сократить до поиска записи в словаре, время тестирования уменьшается до 18 мс. (при начальных 144).
Так что, использование словаря выполняется быстро. Теперь надо посмотреть насколько быстро можно 
выполнять функции нахождения множеств решений.

Сделал формирование нужных структур, теперь можно будет проверить идею расположения базы данных в оперативной
памяти. Пока изменилось время построения промежуточных структур. Оно достигло 4 сек. Правда временно формируется
два словаря, потом будет один.

Ура! Теперь spO выполняется 29 мс. Это несколько больше "нулевых" 18 мс., так что наверное это и есть реальная
скорость. 

Попробую подвести итог. Было 700 мс, стало 29 мс. Выигрыш более, чем в 20 раз! Об этом стоит подумать. 

Провел измерение (домашний компьютер). Смесь тестов (все кроме получения данных) выполнена за 40 мс.
В традиционном варианте это 900 мс. Вроде и получается ускорение более, чем в 20 раз.

Не знаю, правильно ли, но я сделал получение множества литералов по субъекту и предикату. Правда на 
текущем тесте, подтвердившем правильность 6624 обработок и неправильность 393, время выполнения было 9 сек.
Повторно - 1.2 сек.

Возможно, это останется самым затратным по времени преобразованием... Надо будет только обеспечивать то,
чтобы декоидрование литералов производилось по необходимости.

Вроде, получилось... С теми же характеристиками по совпадению результатов, вычисление на объектах 
заняло 139 мс. 
Разница менее значительная, чем для других обработок, но все же - в 8-9 раз!

Только надо будет сообразить как не делать декодирование для каждого вычисления. 
Итак, комплексный тест, проверяющий все 3 вида обработок, дал 8312 совпадения и 393 несовпадения.
И выполнялся 1915 мс. (1907, 1930, 1907)
При использовании объектного построения, получились те же характеристики по совпадениям, тесты
выполнялись 165 мс. (170, 165, 167).

Для 10-миллионных данных, рабочая загрузка графа длилась 41 сек. Тесты выполнились за 3 сек. 
правильность результатов другая. По мере загрузки данных, было занять более 300 мб ОЗУ.
tree_fix.pxc занимает 240 Мб., literals.pac - 478 Мб.

После локального разогрева, результаты получаются лучше. - 201 мс.

20140705 11:16
Перезагрузил компьютер. Активизация и выполнение теста произошло за: 70 сек. - активизация, 4.2 сек. - исполнение.
Повторно. 40 сек. и 202 мс.

Чего я хочу? Я хочу управляемости в данных процессах. Попробую подогреть ячейку с данными.
Разогрев ячейки с литералами выполняется за 12 сек. 

Контрольный эксперимент (10 млн. триплетов, домашний компьюетер)
ОЗУ 313 Мб.
Построение графа 70 сек.
разогрев 13 сек.
выполнение тестов 435 мс.
Повторно
64 сек., 11.8 сек., 230 мс.

20140708
Провожу контрольный эксперимент на рабочем компьютере (10 млн. триплетов)
ЗАгрузка данных, подготовка базы данных - около 60 сек.

Построение графа 17.5 сек., выполнение тестов 190 мс.

20140714 12:48
Провел эксперимент на рабочем компьютере. 
Для 1 млн. триплетов. 
Загрузка занимает 8.8 сек.
Построение графа 1.8 сек., выполнение тестов 27 мс.

Сделал опцию работы без загрузки графа (FillGraph)
Получается: построение графа 12 мс., выполнение тестов 381 мс.

====== 10 млн. триплетов, кабинетный компьюетр =======
Загрузка и формирование графа 190 сек. (в следующем запуске было 157 сек.) было использовано 477 Мб. ОЗУ 
Построение графа 12 мс., выполнение тестов 452 мс.

После перезагрузки 
Построение графа 288 мс., выполнение тестов 33.5 сек.

Если перезти на граф в ОЗУ
Построение графа 30 сек., выполнение тестов 140 мс.

















 
   

