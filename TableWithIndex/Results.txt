Результаты тестирования

SQLTest
подготовка, загрузка, индекс 1, индекс 2, выборка записей по 10 идентификторам (мс.)
После перезагрузки:
7470, 5957, 397, 153, 46, 14
В стационарном режиме (после нескольких прогонов): 
121, 3332, 47, 143, -, 16 
458, 3629, 48, 64, 3, 6

Без загрузки и индексации:
После перезагрузки
7342, 246
443, 55

После нескольких прогонов
303, 28
459, 52
306, 13

PolarTest
Загрузка данных 110 мс.
Построение индекса 288 мс.
109, 226
Использование вместо Sort() SortComparison() дало 4.8 сек.
Добавим время первого пропуска и суммарное время 10 поисков
112, 223, 7, 8
108, 225, 6, 7
Если убрать вывод в Console
106, 223, 5, 2
107, 225, 4, 2

После перезагрузки
112, 226, 5, 2
Если без создания ячейки и индексации
27, 2
Даже с выдачей записей на консоль
42, 4
30, 3

Теперь я сделаю работу со всеми записями, имеющими поле name
Получились результаты:
SQLTest
597, 8991, 482, 4, 12
3934, 7938, 573, 5, 14
Count()=35572

Теперь буду загружать файл tm.xml

SQLTest

Подготовка, загрузка, индексирование, первый Select, 10 Select'ов
8.8 сек., 26 сек., 1.2 сек., 4 мс., 13 мс.
Всего записей 118287
Еще раз:
1.1, 17, 583 мс., 3, 7
размер базы данных 63 Мб.

PolarTest

-, 358 мс., 2262 мс., 6, 5
Объем базы данных: 7.7 Мб + 8.1 Мб (индекс)
-, 346, 2278, 7, 5
Число записей 123002

SQLTest

11 сек., 20.9 сек., 1117, 5, 14
Количество записей - то же: 123002
Размер БД все тот же: 63 Мб.

Итак, пробежуточные выводы. PolarDB проигрывает (в некоторых режимах) MS SQL при индексации. Но сильно выигрывает при
холодном старте и при загрузке. Снова проведу эксперименты, только без загрузки.

Тест без загрузки
-, -, 12.5 сек.(!), 85 мс.
Повторно:
9.6 сек., 227 мс.
1.2, 85
1.0, 86
5.3, 671 мс.
Последний результат получен после сброса sqlservr.exe

PolarTest (без загрузки)

31 мс., 5 мс.
30, 4

=======================
Заменил схему индексации
Тест SemiIndex
загрузка 900 мс.
первый GetById 12 мс.
10 GetById 2 мс.

Без загрузки:
33, 3
поиск по текстовому образцу 5 мс.

На рабочем компьютере
690, 7, 3
717, 15, 0, 0

Без загрузки
-, 19, 1, 4
-, 15, 0, 0

Для двухмиллионника:
5480, 9, 6, 7
5264, 9, 23, 7

Без загрузки
-, 31, 5, 6
-, 30, 6, 7

Более или менее стабильно. Правда флуктуации имеются и могут повлиять на изменения. Но все же надо попробовать другую схему.

FreeIndex test
Загрузка 522. 
для двухмиллионника загрузка 1.8 сек. (Наверное надо радоваться!)

Вроде начинает работать
для 0001.xml
без загрузки -, 21, 4
_, 18, 2 (регулярно)

С загрузкой
513, 2, 2

Для двухмиллионника
1706, 2, 3

Сделал новый вариант индексов для id.
0001.xml:
загрузка 191, индексирование (один индекс) 585, первое чтение по id 2, 10 чтений по id 2

Двухмиллионник
404, 2118, 2, 3

Причем дополнительно, xml-файл загружался секунд 12. 

Без загрузки и индексации:
-, -, 19, 3

Вполне приличные результаты.

С вычислением двух индексов и поиском по образцу
0001.xml
168, 1243, 1, 1, 13
191, 1267, 3, 2, 12

=================
План доведения индекса до демонстабельного состояния.
+1. Подкорректировать название и сигнатуру методов класса FreeIndex
*2. Сформировать соглашение о том, что deleted является первым (нулевым) полем, подкорректировать индексы и определения
*3. Сделать использование deleted в методах доступа
4. Сделать и проверить методы Delete, Replace, Append (может назвать его Insert?).
5. Сделать и проверить общую композицию индекса. Поскольку таблица может быть единой, и индекс не надо множить по размерам.

Добавил фильтрацию вводимых (Load) в индекс данных по признаку deleted. Время индексации увеличилось до 1600-1800. Может
надо добавить метод типа GetObject  

Эксперимент с 1 млн. целых чисел.

Загрузка 435 мс.
Создание индекса 11547 мс. (11.5 сек.)
Первый поиск 5 мс.
10 поисков 4 мс.

Без загрузки (при подсоединении к готовым файлам)
Первый поиск 20 мс.
10 следующих поисков 4 мс.

Случается какая-то заторможенность. Обычно это после долгого "висения" и неиспользования студии. Сейчас в прогоне получилось:
3405, 14302, 41, 8
повторно:
380, 11743, 5, 4

Фиксирую результаты прогона теста rdfengine
11, 3, 22, 1, 16, 130, 489 (Это после многократных исполнений)
После практически "холодного" старта (я не запускал программу 2 часа и VS была выключена) результаты удручают:
523, 910, 32, 0, 1213, 13623, 73765 (!)
При повторном запуске, хорошие результаты возобновились.
Снова после холодного старта, были отклонения от "стандарта", но... только в последнем времени (?). Получилось 8.3 сек.
Надеюсь, на серевере, времена обработки будут весьти себя и регулярнее и предсказуемее.

Теперь вернусь к разработке индекса. Надо сделать: два индексных массива, добавление и уничтожение записей.

20131110 20:21
Пропустил последний тест на "кабинетной" машине. Результаты, включая загрузку
Загрузка 744
Индексирование 8338
2, 1, 10, 0, 6, 63, 206

Прогон без загрузки:
4, 1, 11, 0, 7, 49, 202

Раза в 2.5 быстрее. 

Дома.
Похоже, я понял одну из причин замедления создания портрета. Дело в объединении родственных узлов. 
Видимо создавать конструкцию вида:
<inverse prop="property">
  <record ... />
  <record ... />
  ...
</inverse>

экономнее, чем

<inverse prop="property">
  <record ... />
</inverse>
<inverse prop="property">
  <record ... />
</inverse>
...

Но для этого, нужно на ранних стадиях обработки знать имя свойства, по которым имеются обратные отношения. 

Вроде придумал некоторую схему. Меня подвело следование идее векторной индексации. Пусть у нас есть множество
записей так, как и сейчас. Теперь по каждой ссылки из записи, мы породим рядок в специальной индексной таблице.
В таблице будут: offset записи-источника, идентификатор свойства (предиката), по которому источник ссылается на
приемник, идентификатор приемника. Последнее, может быть стоит заменить на offset записи-приемника. Но об этом
подумаю позже. Таким образом, имея идентификатор, мы (при наличии индекса на этом поле) легко можем найти 
еще два существенных значения - offset источника и идентификатор предиката. В принципе также можно было бы иметь
составной индекс. Тогда легче было бы доступаться к обратным ссылкам с конкретным предикатом. Также в принципе,
можно было бы распространить схему на прямые ссылки. Но это - позже. По идентификатору, мы получаем множество
всех ссылок, к нему ведущих, причем каждая ссылка снабжена идентификатором предиката. Остается сгруппировать
ссылки по предикатам и схема реализации готова. По этой схеме не нужно будет "ковыряться" в деталях каждой записи,
"выискивая" нужную информацию. Таблицу можно еще расширить, например добавив тип записи-источника. Для обратных 
ссылок это сейчас не актуально. Было бы актуально для прямых, но мы их реализуем по другой схеме. 

20131111 16:34 на работе
Главная моя задача - найти и исправить ошибки в конструкциях для RDF. 

Пару ошибок исправил. Начинает "дышать". Нашел нижнюю грань по построению (моего) портрета, это 5-6 мс. 
Именно столько времени тратится на выборку всех обратных отношений. 

Результат прогона (без загрузки и индексирования)
4, 2, 13, 0, 11, 55, 212

В общем, результаты приблизительно те же. 
Несколько хуже - выборка базового портрета с обратными отношениями. Это видимо потому, что я попытался сделать группирование.

Вернул вариант простого векторного индекса для индексирования имен. Результат - 11 мс.

Однако, группирование нужно. Хочу попробовать его сделать прямо в структуре данных. Итак, есть следующие таблицы:
records - последовательность записей из 5 полей [deleted, id, type, fields: [predicate, data, lang], [predicate, obj]] 

20131112 05:47 дома
6, 3, 19, 1, 21, 125, 487

Продумывание привело к следующим соображениям:
1. Концептуально правильно будет делать "мягкое" группирование. Т.е. формировать таблицу [offset, id, predicate] так, 
что таблица отсортирована по id, а вслед - по predicate. 
2. Выборка ведется по id парами {offset, predicate}. Если в задаче нужно группирование, то его можно сделать "снаружи". 
Для выбора варианта алгоритма, желательно поток предварять количеством пар. Если их много, можно как-то оптимизировать.
3. Желательно отсортировать варианты (обратных отношений) по имени предиката. 
4. В ядре PolarDB желательно иметь: а) сортировку с указанием диапазона; б) бинарный поиск с вычислением диапазона;
в) выборку потока по диапазону.

08:33
Попробую реализовать новые идеи.

Сортировка с указанием диапазона уже реализована. Теперь бинарный поиск с указанием диапазона.

11:28
Вроде сделал. Теперь надо испытать, а если будут проблемы, то еще и отладить. 

На тесте поиска подстроки проверил и даже исправил одну ошибку. Теперь поиск в тесте выполняется за 13-14 мс., тогда
как раньше выполнялся за 19-22 мс. 

Теперь подумаю об оптимизации GetItemByIdBasic. И хотя это - не ключевая процедура, на ней я смогу попробовать 
усовершенствовать решение без форматных построений. 

Пока эта процедура выполняется на моем портрете 24-26 мс. Это многовато. Прямые отношения строятся 2-3 мс. Так что 
совершенствовать надо обратные отношения. Но Андреевском портрете - 22-23 мс.
При замене BinarySearchAll на BinarySearchDiapason уже получился выигрыш. Портрет строится 13-14 мс. (до 16).

20131113 06:41
Работаю уже больше часа. Делаю вторичный индекс для FreeIndex. Что-то написал, что-то сработало. Надо проверить.

Вроде сортирует. Но индекс теперь строится более 25 секунд. Попробую еще раз.
Да. Загрузка 5.5 сек., построение индекса - 25.5 сек.
Пока на это обращать внимание не буду. 

Теперь попробую ускорить создание базового портрета.

07:21
Ура! Вроде заработало, вроде правильно. И точно быстрее. Вместо 13 мс. теперь 8 мс. Это означает, что суммарно, я ускорил
построение базового информационного портрета в 2.5 раза!

19:34
Результаты экспериментов и обдумывания, приводят меня к мысли, что выбранный путь и сложен и неэффективен. Хочу попробовать
вернуться к старой идее - в "центр" рассмотрения поместить триплет. Это - таблица с тремя "стандартными" колонками и
нестандартной колонкой "deleted". Можно воспользоваться свободным индексом, но это не отсортирует группы, одинаковых по
субъекту или объекту триплетов по предикату. Похоже - это ключ к решению проблемы эффективности. Вот эту ключевую проблему
можно будет решить если сделать вместо FreeIndex другое индексное решение - с двумя ключами первичным и вторичным. Только 
придется несколько модифицировать сортировку. 

Посмотрел код. Вроде даже не надо писать новую процедуру сортировки, можно воспользоваться методом SortByKey. Теперь 
посмотрю на код FreeIndex. 

Начало положено. Загрузил записи и триплеты. С записями я уже знаю что делать. Время загрузки 1.5-1.9 сек.

Теперь поработаю с записями.

Загрузка 1.7 сек., индексирование - 9 сек.

Проверю работу на простых тестах.

Получилось 23, 3, 13
Без вывода результатов
21, 3, 13

Не могу понять почему у меня раньше первая цифра получалась существенно меньше.

Теперь наступила очередь самого сложного - использования гибкого индекса. Попробую, что-ли...
Прямой индекс загрузился. Интересно, правильно ли? Сейчас попробую проверить. Только проверить можно лишь обратный индекс.

Теперь строятся оба индекса. Время построения всех индексов - почти 20 секунд. 

Первичная проверка обратных отношений прошла успешно. Теперь поработаю над базовым получение портрета.

20131114 05:21
Построение базового портрета (почти) работает и выполняется (на Андрее) 6 мс. Похоже, это успех! Причем никакого 
группирования обратных ссылок не делается. Уже 5 мс. Прото убрал построение массива для отладки. Теперь попробую 
воспользоваться решением с группированием.

Сгруппировал. Время не улучшилось и осталось 5-6 мс. Но мне кажется, это приемлемо. И даже - оптимистично.

Пора переходить к главной процедуре - построению форматного портрета. 

Итак, промежуточные результаты:
21, 3, 13, 7
Последняя цифра - мой базовый портрет. Портрет Г.И. строится за 13 мс.

Текущая цифра по портрету - 3.

Облом... На следующей стадии, получилась цифра более 400 мс. Похоже, где-то я напартачил. Надо поотлаживаться. 

17:59
Скурпулезно пытаюсь сделать форматное вычисление портрета более эффективным. Пока удовлетворяет обработка полей. 
Нахожусь на первичной стадии обработки обратных отношений. Результаты более или менее удовлетворяющего меня этапа:
0-6 мс. вычисление портрета до стадии идентификаторов обратных объектов. 
30 мс. - 10 портретов.
Добавление следующей стадии, заключающейся в покомпонентном поиске местонахождения 125 айтемов, утраивает время работы:
19, 96; 
20, 100;

Добавление финальной стадии обработки обратных отношений, не добавило времени обработки. Хотя там есть GetItemById,
но с уже вычисленным айтемом.

времена: 
20, 90; 
20, 96; 
20, 100; -- последнее - два раза.

Опять дома.
Загрузка выполняется 2 сек. Индексирование 20 сек.
времена: 3, 3, 12, 11, 52, 193 мс.

Все объяснимо. Надо реализовать идею множественного запроса к индексу. Задаю сразу пачку идентификаторов. Сортирую
их, потом аккуратно начинаю бинарный поиск. В один Log шагов получаю все значения. Была проблема с использованием 
гибкого индекса. Попробую ее преодолеть. Видимо придется расширить на пару методов ядро в части PaEntry.

Кстати, производительность вычислений при использовании PolarDB может существенно зависеть от дефрагментации диска.
Надо будет проверить и отразить этот момент в документации.

20131115 11:41
Опять плохо спал. Все не давали покоя проблемы с алгоритмами. Я попытался написать программу множестовенной выборки из
индекса. Плохо получалось, код - какой-то корявый. И к тому же я сообразил, что мой оптимизм по поводу возможного 
ускорения базируется на неверной предпосылке, что за Log(N) шагов все значения будут вычислены. Но это не совсем так.
Программа выборки будет идти на по единственному пути к значению, а будет сначала ветвиться. И количество ветвей,
возможно, сопоставимо с K, где K - количество ключей запроса. Так что так и получится K * Log(N) шагов. Я даже
проверять это заключение не захотел. Я возвращаюсь более интенсивному использованию оперативной памяти. Короче, я
завел словарь         
private Dictionary<string, PaEntry> item_dic = null;
куда помещаются (на тесте за полторы секунды) пары идентификатор айтема - его вход. Наверное можно сэкономить и помещать
только offset. Результаты не то, чтобы восхитили, но выглядят нормальными. Последний прогон (без загрузки)
Инициализация (загрузка словаря) 1480
GetById 1
10 GetById 0
Search 10
GetItemByIdBasic 13
GetItemById 132
10 GetItemById 515 (теперь это полный портрет)

На рабочем компьютере должно быть быстрее. Код получился простым и логичным. Схема реализации добавлений и удалений 
достаточно понятна. Наверное, остановлюсь на этом решении. 

Для проверки, запустил программу без словаря. Получилось:
17, 8, 4, 14, 14, 295, 1042

Можно сказать, что в 2 раза хуже. Пойду на теннис, подумаю над продолжением работы.
Кстати, и без словаря, программа потребляет 100 Мб.

14:42
Надо подчистить код, может что-то еще улучшится.

Попытка сэкономить на загрузке словаря из набора записей не удалась. Загрузка производится 3 сек. Последние цифры
по формированию портрета 
GetItemById 106 
10 GetItemById 439

Можно еще сэкономить на частичном возвращении старой схемы, когда мы в записи оставляем прямые ссылки. Пожалуй сделаю это.
Но сначала, поставлю что-нибудь готовиться. Пообедать надо.

Расширил запись, но пока не использовал. Время загрузки 2.7 сек. Время индексации 26 сек. Оно может быть уменьшено 
если не вычислять прямой индекс. 

Попробовал на GetItemByIdBasic.
Получилось время 11 мс. Вроде меньше 13 мс., но это мало что говорит. Надо попробовать на форматном портрете.

Вроде сделал, вроде работает. Вроде даже результаты чуть-чуть лучше. Но они нестабилные.
первая цифра то больше 100, то 67. И 10 портретов также - то меньше 400, то больше. Сделаю несколько пропусков.

67, 459
89, 311
109, 343
91, 285
89, 288

Тенденция понятна. Теперь хорошо бы проверить как это все сопоставляется с измеренными результатами по другим движкам.

Рабочий компьютер
Инициализация 15
Load 979
Indexes 8953
GetById 1
10 GetById 1
Search 6
GetItemByIdBasic 5
GetItemById 28
10 GetItemById 114

Особенно впечатляют последние цифры...

Без загрузки, последние цифры:
40, 110.
Также интересно время на формирование словаря - 570 мс. Это уже реальное время!
Размер базы данных, как и ожидалось, подрос и стал 81.4 Мб.




 



 
 







 


 







   
 

