
Решил сделать "чистенький" проект по работе с "правильным" RDF. Имеется ввиду типизация полей данных.
Если я правильно понимаю стандарт RDF, значения полей данных могут быть типизированы. То есть,
объектом подобной тройки будет константа вида:
... "значение"^^<объект типа>

Если этой части константы нет, то подразумевается стандартная строка с известным типовым узлом:

"value"^^xsd:string
или 
"value"^^<http://www.w3.org/2001/XMLSchema#string>
 
Будем поддерживать: 
xsd:integer

В дальнейшем, добавим:
xsd:date
xsd:dateTime
xsd:boolean или как он там называется
xsd:number или как-то по-другому (xsd:decimal, xsd:double!) 
 
Другие типы можно будет добавлять по мере необходимости.

Теперь о языковой специализации. Если я правильно понимаю логику RDF, при его применении, фиксируется то же
значение типа, что и без указаний типа и специализатора - xsd:string.
И только в этом случае, этот специлизатор (@ru) может возникнуть. Почитаю стандарт. 

Почитал. Что-то там не сходится. Получается, что просто константная строка не сравнима с типизованной строкой,
так же как и строкой с языковым специализатором. В Turtle строка и типизованная строка идентичны. Я пойду дальше.
У меня будет храниться объединение:
RLiteral = 
	integer^integer,
	string^{s: sstring, l: sstring},
	date^longinteger,
	...

Ввод данных буду производить с помощью упрощенного парсера ttl.

Сначала отладил программу на стандартных данных. Построение базового портрета занимает на домашнем компьютере
23 мс. для 10 (стандартных) идентификаторов и это после разгона. Попробую загрузить берлинский миллион.

Загрузил. На берлинском миллионе, базовый портрет получается в первый раз за 2350 мс. Пять следующих 
портретов вычислены за 7 сек. При повторном запуске, результаты - лучше. Первый портрет - 42 мс., пять
следующих - 23 мс. База данных - 247 Мб. Загрузка данных и индексация производилась 40 сек. (15 сек. - загрузка).

Следующая задача, которую хочется решить - это гибкое управление сортировкой-выборкой. Я имею ввиду то, что
хотелось бы отсортировать индексы первично по субъекту (или объекту, соответственно) и вторично - по предикату.
Тогда можно будет производить выборки и по одному заданному субъекту и по паре субъект-предикат. Вроде ничто не
мешает. Посмотрю код.

Посмотрел, сделал. Загрузка в сортировкой по парам субъект-предикат и объект-предикат выполняется за 111 сек.
Построение портретов вроде работает. Пять портретов делаются за 25 мс. Теперь сделаю нужные процедуры.

Решил, что двойной сортировки недостаточно и теперь "главный" индекс объектных триплетов вычисляется по сортировке 
субъект-предикат-объект. Время загрузки почему-то уменьшилось. 
68 сек. загрузка.
Теперь появляются осмысленные результаты, потом надо будет их сравнить с вычисленными через Sparql.

57, 65, 213, 60, 53, 51  время=538

476 сек.
30 мс., 50 мс. - 6 прогонов первого теста.

20140212 04:29
Решил поработать. Сделал удобный вариант теста. Это 1 млн. берлинских триплетов. Это первый берлинский запрос
и это некоторая заметрая разница между тем, что получается и что можно было бы ожидать. Тестирование на
домашнем компьютере дает 26-30 мс. для выполнения 6 запросов с различными стартовыми точками (идентификаторами).
Это при фиксации только первого предложения Sparql-запроса. Использование фильтрующего второго - дает уже
515-528 мс., третьего - 685 мс. Добавление вычисления поля добавляет совсем не много - 700 мс. 
Если убрать фильтры, получится 540 мс. Но там заметно больше (раза в 4) веточек, которые ранее убирались 
фильтрацией. 

Задача номер 1 - сделать фильтрацию типа проверки существования триплета (существенно) более эффективной.

Этап 1.
Завожу массив битовых пар в виде массива целых чисел. Число битовых пар N_bpairs. Его надо будет вычислить.
Но пока его положу 8 М, т.е. число битов 16 М, число целых 0.5 M, что равно 524288, что соответствует 2**19.
Избыточность такой шкалы - 8, надеюсь этого хватит. Индекс массива битовых пар будет 2**23
Далее, для объектных триплетов вычисляю индекс как Hash(subject) xor Hash(predicate) xor Hash(object) и
оставляю в числе 23 бита. Операция xor в Си выражается символом ^. 
Полученным индексом я выбираю два бита (arr[ind >> 4] >> ((ind & 15) << 1)) & 3;
Два бита кодируют "попадание" триплета в данный код. 
0 - нет "попадания"
1 - есть единичное попадание
2 - есть несколько попаданий

Запись двухбитного кода в шкалу по индексу осуществляется оператором
arr[ind >> 4] = arr[ind >> 4] & (~(3 << ((ind & 15) << 1))) | ((value & 3) << ((ind & 15) << 1));
где v - записываемый код.

Наверное, надо оформить шкалу классом. Попробую.
Некоторый код написал. Пока шкала формируется "динамически" - в оперативной памяти и передпропуском тестов.
после "разгона", шкала вычисляется 1187 мс.
Сделаю проверку шкалы.

Проверка показала достаточно логичные результаты. Для нашего миллиона триплетов, 8 млн. позиций - пустые,
327 тыс. - единичные, 58 тыс - двойные. Ошибочных кодов нет.

Вроде получилось. Время выполнения 6 запросов - 306 мс. Но там есть "неудачный" (мало фильтрует), он 
среднее время несколько увеличивает. 

   







 