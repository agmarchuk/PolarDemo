
Решил сделать "чистенький" проект по работе с "правильным" RDF. Имеется ввиду типизация полей данных.
Если я правильно понимаю стандарт RDF, значения полей данных могут быть типизированы. То есть,
объектом подобной тройки будет константа вида:
... "значение"^^<объект типа>

Если этой части константы нет, то подразумевается стандартная строка с известным типовым узлом:

"value"^^xsd:string
или 
"value"^^<http://www.w3.org/2001/XMLSchema#string>
 
Будем поддерживать: 
xsd:integer

В дальнейшем, добавим:
xsd:date
xsd:dateTime
xsd:boolean или как он там называется
xsd:number или как-то по-другому (xsd:decimal, xsd:double!) 
 
Другие типы можно будет добавлять по мере необходимости.

Теперь о языковой специализации. Если я правильно понимаю логику RDF, при его применении, фиксируется то же
значение типа, что и без указаний типа и специализатора - xsd:string.
И только в этом случае, этот специлизатор (@ru) может возникнуть. Почитаю стандарт. 

Почитал. Что-то там не сходится. Получается, что просто константная строка не сравнима с типизованной строкой,
так же как и строкой с языковым специализатором. В Turtle строка и типизованная строка идентичны. Я пойду дальше.
У меня будет храниться объединение:
RLiteral = 
	integer^integer,
	string^{s: sstring, l: sstring},
	date^longinteger,
	...

Ввод данных буду производить с помощью упрощенного парсера ttl.

Сначала отладил программу на стандартных данных. Построение базового портрета занимает на домашнем компьютере
23 мс. для 10 (стандартных) идентификаторов и это после разгона. Попробую загрузить берлинский миллион.

Загрузил. На берлинском миллионе, базовый портрет получается в первый раз за 2350 мс. Пять следующих 
портретов вычислены за 7 сек. При повторном запуске, результаты - лучше. Первый портрет - 42 мс., пять
следующих - 23 мс. База данных - 247 Мб. Загрузка данных и индексация производилась 40 сек. (15 сек. - загрузка).

Следующая задача, которую хочется решить - это гибкое управление сортировкой-выборкой. Я имею ввиду то, что
хотелось бы отсортировать индексы первично по субъекту (или объекту, соответственно) и вторично - по предикату.
Тогда можно будет производить выборки и по одному заданному субъекту и по паре субъект-предикат. Вроде ничто не
мешает. Посмотрю код.

Посмотрел, сделал. Загрузка в сортировкой по парам субъект-предикат и объект-предикат выполняется за 111 сек.
Построение портретов вроде работает. Пять портретов делаются за 25 мс. Теперь сделаю нужные процедуры.

Решил, что двойной сортировки недостаточно и теперь "главный" индекс объектных триплетов вычисляется по сортировке 
субъект-предикат-объект. Время загрузки почему-то уменьшилось. 
68 сек. загрузка.
Теперь появляются осмысленные результаты, потом надо будет их сравнить с вычисленными через Sparql.

57, 65, 213, 60, 53, 51  время=538

476 сек.
30 мс., 50 мс. - 6 прогонов первого теста.

20140212 04:29
Решил поработать. Сделал удобный вариант теста. Это 1 млн. берлинских триплетов. Это первый берлинский запрос
и это некоторая заметрая разница между тем, что получается и что можно было бы ожидать. Тестирование на
домашнем компьютере дает 26-30 мс. для выполнения 6 запросов с различными стартовыми точками (идентификаторами).
Это при фиксации только первого предложения Sparql-запроса. Использование фильтрующего второго - дает уже
515-528 мс., третьего - 685 мс. Добавление вычисления поля добавляет совсем не много - 700 мс. 
Если убрать фильтры, получится 540 мс. Но там заметно больше (раза в 4) веточек, которые ранее убирались 
фильтрацией. 

Задача номер 1 - сделать фильтрацию типа проверки существования триплета (существенно) более эффективной.

Этап 1.
Завожу массив битовых пар в виде массива целых чисел. Число битовых пар N_bpairs. Его надо будет вычислить.
Но пока его положу 8 М, т.е. число битов 16 М, число целых 0.5 M, что равно 524288, что соответствует 2**19.
Избыточность такой шкалы - 8, надеюсь этого хватит. Индекс массива битовых пар будет 2**23
Далее, для объектных триплетов вычисляю индекс как Hash(subject) xor Hash(predicate) xor Hash(object) и
оставляю в числе 23 бита. Операция xor в Си выражается символом ^. 
Полученным индексом я выбираю два бита (arr[ind >> 4] >> ((ind & 15) << 1)) & 3;
Два бита кодируют "попадание" триплета в данный код. 
0 - нет "попадания"
1 - есть единичное попадание
2 - есть несколько попаданий

Запись двухбитного кода в шкалу по индексу осуществляется оператором
arr[ind >> 4] = arr[ind >> 4] & (~(3 << ((ind & 15) << 1))) | ((value & 3) << ((ind & 15) << 1));
где v - записываемый код.

Наверное, надо оформить шкалу классом. Попробую.
Некоторый код написал. Пока шкала формируется "динамически" - в оперативной памяти и передпропуском тестов.
после "разгона", шкала вычисляется 1187 мс.
Сделаю проверку шкалы.

Проверка показала достаточно логичные результаты. Для нашего миллиона триплетов, 8 млн. позиций - пустые,
327 тыс. - единичные, 58 тыс - двойные. Ошибочных кодов нет.

Вроде получилось. Время выполнения 6 запросов - 306 мс. Но там есть "неудачный" (мало фильтрует), он 
среднее время несколько увеличивает. 

Теперь настало время проверить идею с формирование Linq-запросов, похожих на Sparql. Идея вырисовывается
следующей:
Для RDF-движка определяем методы, похожие на триплеты. 
IEnumerable<RPack> spo(this.IEnumerable<RPack> pack, object s, object p, object o);
Другие методы имеют такой же интерфейс (!) и называются аналогично: Spo, spO, Spd и т.д.
Причем большая буква символизирует то, что соответствующий параметр является "приемником" 
вычисляемых значений. Если эта буква маленькая, то это уже вычисленное значение или константа. 
Параметры s, p, o могут быть либо целым значением, либо строкой. В первом случае, это означает
индекс массива, где находится строка, соответствующая этому значению. Во втором случае, строковая
константа является собственно значением Entity. Для данных (d) множестов типов расширяется на
возможные типы данных: строки, целые, вещественные, даты, логические и т.д. В случае, когда
параметр помечен большой буквой, допустимо только целое значение индекса массива, куда будет 
записано то, что вычислено.    
Рассмотрим эти методы несколько подробнее. 
spo является фильтром. Этот метод определяет есть ли в хранилище объектный триплет с соответствующими
значениями субъекта, предиката и объекта и если есть, значение pack пропускается. Остальные варианты -
отбраковываются. Если есть неопределенное значение, то его надо определять. Соответственно, по известным
частям триплета порождается множество вариантов, которые "запускаются в оборот". 
Фильтр - это фильтр вариантов, задающий предикат фильтрации. Опция - дополнительная настройка над
потоком вариантов, размещающия неопределенным значением какую-то часть переменных и далее, вычисляющая 
или не вычисляющая эти значения. 
Объединение - некоторый разветвитель, обеспечивающий выполнение дизъюнкции наборов вариантов.

Попробую, что-ли...

Попробовал, получилось! Есть еще недоделки, но код вида:

                string bsbm = "http://www4.wiwiss.fu-berlin.de/bizer/bsbm/v01/vocabulary/";
                string bsbm_inst = "http://www4.wiwiss.fu-berlin.de/bizer/bsbm/v01/instances/";
                // query 1
                object[] row = new object[3];
                int _produc = 0, _value1 = 1, _label = 2;
                var quer = Enumerable.Repeat<RPack>(new RPack(row, ts), 1)
                    .Spo(_produc, bsbm + "productFeature", bsbm_inst + "ProductFeature19")
                    .spo(_produc, bsbm + "productFeature", bsbm_inst + "ProductFeature8")
                    .spo(_produc, "http://www.w3.org/1999/02/22-rdf-syntax-ns#type", bsbm_inst + "ProductType1")
                    .spD(_produc, bsbm + "productPropertyNumeric1", _value1)
                    ;

вполне похож на Sparql-прототип. И вполне легко формируется на основе прототипа. При этом, исполняется на
домашнем компьютере (на 1 млн.) за 61 мс.
 
Я несколько приостановился на типах данных (литералов). В принципе, в разделе Triple определен класс Literal,
которым надо пользоваться в этих местах. Соответственно, для spD аргумент данных должен быть оформлен следующим
образом: либо это целый индекс, либо значение класса Literal. В массиве хранения данных row, позиция значения
переменной поля будет занимать значение типа Literal. Надо сначала вернуться к вводу данных и задействовать 
тип, если он указан.

Первый тест удалось выполнить полностью. Результаты совпали. Надо сделать некоторые другие тесты.

Сделал тесты 1, 2, 3, 6
Результаты прогона на домашнем компьютере тестов на 1 млн. дают следующие резвльтаты:
422, 66, 876, 1801
Не очень, но это измерения.
83, 2, 270, 1167 - второй прогон

20140217 10:50
Я сделал довольно принципиальную ошибку. Это касается использования шкалы для проверки существования конкретного
(объектного) триплета. Я посчитал, что выгодно шкалу коидровать двумя битами с кодами 0 - нет триплета, 1 - есть один
триплет с данным кодом, 2 - есть больше одного триплета с данным кодом. Однако, данная логика в вопросах проверки
не сработала. Дело в том, что проверяться может любое сочетание субъект-предикат-объект. И код этого сочетания может 
совпасть с кодом одиночного триплета, имеющего значение 1. В итоге, при проверке, я выдаю, что этот триплет существует,
а на самом деле - нет. 

Переделывать шкалу - требует времени. Я пока оставлю двухбитный вариант, просто подправлю его использование.

Вроде заработала новая версия, наверное - "задышала". Испытываю на 1 млн.
Загрузка 23 сек.
Первое исполнение теста 151, 1, 280, 981
Второе - столько же.
После перезагрузки 10163, 122, 10979, 13284 - забавно...
Загрузка 18 сек. Объем базы данных 70 Мб.

Загрузил 10 млн. время 335 сек.
Времена: 1066, 617 (частичный 1_1), 2225, 12133 мс.

Снова реализую и внедряю шкалу. Сначала шкала создается динамически и проверяется ее работоспособность.
На 1 млн., 81 тыс. - разнича между числом триплетов и числом точек на шкале. Это около 20 %

Времена без шкалы: (количества результатов 51, 0, 219, 303)
68, 0, 112, 376
Со шкалой
1 - полный отказ 
9 - работа со шкалой (56 результатов)
83 - работа без шкалы (56 результатов)
1 - без фильтрации (223 результатов)
29 - без шкалы (56 результатов)


Загрузка данных в 10 млн. триплетов. Время загрузки - 144 сек., Объем данных - 688 Мб.
Времена исполнения запросов:
241, 1, 868, 4507 мс.
238, 1, 844, 4479

  
Перенес систему на рабочую машину. Загрузка 1 млн. длится 12 сек. Объем базы данных 84 Мб.
Времена прогона тестов:
30, 15, 62, 255, 221 мс.

10 млн.
Загрузка 174 сек. ОБъем базы данных 823 Мб.
Времена:
120, 111, 448, 2701, 2442


Пришла в голову группа идей по поводу возможностей ускорения выполнения запроса. Есть разные вариации
этих идей. Одна из вариаций довольно проста в реализации. Надо попробовать отсортировать множество
триплетов otriples. Элементы этого множества - записи фиксированного размера, поэтому сортировка возможна.
Для начала, такая сортировка ничему не помешает. Но теперь это множество можно будет использовать
вместо индекса для тех же целей. То есть, задавая s или s-p или s-p-o, можно получать нужные подмножества.
Попробую.

141, 1, 280, 1004
96, 2, 248, 1023

Вроде выигрыш есть. Посмотрю пристальнее и детальнее.

На запросе 1_1 время выполнения ведет себя следующим образом:
3, 32, 37, 58, 58, 76 - в зависимости от этажности запроса
3, 61, 76, 97, 95, 114

Выигрыш явно есть. Теперь добавлю шкалу.
3, 11, 18, 38, 38, 57
- также выигрыш явно есть

Теперь попробую изменить другие места, использующие spo-индекс
Сейчас буду заниматься серьезными оптимизационными работами. Надо записать текущий результат (тест - к-во - время)
1 51 81
1_1 55 58
3 219 259
5 8 1233
6 303 1055

После того, как я прооптимизировал работу с otriples, получились результаты (последняя колонка):
83, 56, 243, 1158, 1006

По крайней мере, не хуже.

Теперь внимательнее посмотрю на исполнение второго теста (1_1).

После трех стадий - 16-17 мс. А было - 18. Не хуже. Добавление четвертой стадии доводит до 37 мс., 
т.е. добавляется 20 мс.

Надо работать с dtriples.

Похоже, что-то получилось. Результаты прогона тестов:
60, 37, 150, 636, 549 Ура! Раза в 2 в ряде случаев время сократилось.

<<<<<<< HEAD
Решил разобраться с теми тестами, где результаты хуже, чем у Виртуозы. Начал с третьего теста. Первая 
часть запроса выполняется хорошо, за 2 мс. и получается 220 результатов. но потом, на выполнение 220 .spD
затрачивается 42 мс. 
Получается, что выполнение одного .spD "тянет" на 5 spD за миллисекунду.

Еще один резерв. Переставление в пятом запросе третьего оператора в конец, сокращает время вычслений
с 610 мс. до 430.

Пришла в голову любопытная идея. У нас есть переменные, которые накапливаются в по мере вычисления.
Сейчас эта переменная - достаточно простая. Для Entity это объект, содаержащий строку или целое (в случае
целочисленного кодирования). А если переменную Entity усложнить? Скажем, добавить пару-тройку полей диапазона
уже произведенного поиска. Так сказать, имитация объектного представления. Первое вычисление переменной видимо
ничего кроме значения не привносит. Но если переменная использовалась в операторе spO, то поместить в нее
дополнительное значение диапазона s*O. Ну и так далее. Тогда (следующее) вычисление spO можно будет вычислить
внутри имеющегося диапазона.

Посмотрю насколько сложно реализовать эту идею.

В общем, мне идея нравится. Практически создается вариант объектного представления. Можно идею развивать 
и дальше, напр. в сторону присутствия объектной информации везде, где мы выходим на объект. Например,
в представлении otriples_spo, можно было бы для каждого o иметь диапазоны прямых и обратных таблиц.

Некоторое изменение схемы Linq-реализации Sparql заключается в том, что теперь и для константных значений
Entity нужны позиции в массиве вычисляемых значений. Кроме того, диапазон может быть пустым, это также надо 
иметь ввиду. 

Итак, попробую написать класс ObjectRowInt в отделаьном модуле.

15 мс. - время 10 вычислений ts.GetSubjectByObjPred(obj, pred).Count();
5 мс. - время 10 вычислений диапазона
17 мс. - 10 раз диапазон + в диапазоне. 

Ура! Разобрался с некоторыми особенностями работы с применяемыми структурами. Пришлось даже сделать изменения 
в ядре. Но теперь я с оптимизмом гляжу в будущее и есть множество мест, где возможны улучшения.

Два триплета в тесте Berlin1 (это перерабатываемый первый тест) выполняются 15 мс. Третий, добавляет до 21 мс.
Попробую модифицировать нужным образом метод _spo.

Вроде модифицировал. Теперь три части запроса срабатывают за 14-15 мс. А две - за 11-12. 

Преодолел некоторые трудности. Теперь первый тест работает. И выполняется за 43 мс. Это вместо 60, которые 
были ранее.      

После перезагрузки, времена следующие (1_1, Berlin1, 1, 2, 3, 5, 6) (Berlin1 и 1 усечены до одной строки):
23, 9, 2, 88, 4340, 2151, 2317 
20, 7, 2, 5, 153, 439, 544

Бинарный поиск 2600-2700 тиков
Вычисление диапазона 6700-7300 ticks
Функция глубины - одинаковая
Добился, чтобы диапазон вычислялся как бинарный поиск. Можно двигаться дальше. 2700-2900 тиков.

Увы... Поторопился рапортовать. Правильное измерение показало 7300-8000 тиков. Я не понимаю причину!!!

Надо считать число чтений из файла. Как это сделать?

Можно через функцию ElementDepth. Попробую.

Попробовал. На данном тесте число обращений к функции глубины - 27. Очень мало и совпадает с таким же числом
для бинарного поиска. Я еще меньше понимаю разницу в эту сторону имея ввиду то, что бинарный поиск генерирует все
209 входов PaEntry. Это не сопровождается чтением данных, но сами структуры формируются. И их гораздо больше, 
чем в случае вычисления диапазона (раз в 10). Попробую поискать данные, где в диапазон попадает больше значений.

Нашел, это тип bsbm:Product у него 2848 элементов в диапазоне. Время 8476, число обращении к глубине 34.
теперь бинарный поиск дает 4700-5177, счетчик обращений к глубине - 34.
Для случайного entity, не попадающего в какой-то идентификатор, получается время 4600 тиков.
Для бинарного поиска - 2400.

Поскольку я не знаю что делать, попробую "покрутить" систему на рабочем компьютере и с большими данными.






Загрузка 10 млн. длилась 174 сек. 
Поиск всех с отсутствующим входом длился 2207 тиков. Повторно 2036. Число доступов к файлу 22.
И здесь также вычисление диапазона выполняется дольше 3800-3824.

Большой тест: диапазон 6400-6500 тиков, поиск 24500 тиков. Найдено 28480 вариантов
Проверил еще раз, действительно вычисление диапазона работает быстрее 6400 тиков, диапазон
также содержит 28480 вариантов! На тесте 1: диапазон 6700 тиков, поиск 4000 тиков, найдено 1441 вариант, 35 "глубин"

Фиксирую результаты прогона тестов на 10 млн (b1, 1, 2, 3, 5, 6).
90, 94, 495, 0, 1935, 2524

Займусь пятым тестом, там должен быть выигрыш от новой схемы интерпретации.

Сделал по-новому 3-й и 6-й тесты: тестрование (b1, 1, 2, b3, 3, 5, b6, 6):
80, 100, 0, 380, 470, 1990, 2950, 2560
88, 92, 0, 377, 457, 1943, 2918, 2413

475-530 тиков.

Происходят некоторые "чудеса", которые я не в силах объяснить. Долго пытался выявить принципиальное различие
в методах BinarySearchAll и BinarySearchDiapason. Кроме того, что бинарный поиск элементов активно использует
циклы и оператор yield return, я ничего существенного не нашел. Сделал рекурсивную процедуру сканирования,
работающую по логике определения диапазона. Фактически, делаются только замер глубины среднего значения и уход 
в рекурсию. Результаты стали похожими на бинарный поиск. Потом взял бинарный поиск и перенес в другое место кода
и переименовал. Думал начну "чистить" и получать "чистый" сканер. Неожиданностью явилось то, что он стал резко
медленнее работать. Было 2600-2700 тиков, стало 20000 тиков. Что же произошло? Поищу.

Похоже, это какие-то особенности исполнительской системы. Или трансляции. Я сециально сделал точную копию 
трех статических методов BinarySearchInside/Left/Right и только переименовал методы. А потом стал присоединять 
методы к разным "пускачам" и смотреть что получится. Получается нечто странное. Штатно, метод бинарного
поиска работает 2600-2700 тиков (Неплохо!). Но иногда либо он, либо эквивалентный ему BinarySearchScan,
дает или 4000 тиков или 20 тыс. тиков. Непонятно...

20140225 05:04
Проснувшись, опять начал думать о задаче... Появилась идея. Возможно, она носит существенный характер. В итоге,
заснуть я уже не могу, надо поработать.

Идея заключается в том, что в нахождении диапазона присутствует два последовательных действия. Первое - 
нахождение первого "нуля", т.е. (любого) значения индекса или entry, на котором функция глубины дает "ноль".
После этого, один процесс Left ищет "минимальный ноль", второй Right - максимальный. Можно отметить, что
не видно избыточности в разбиении вычислений на три этапа. Еще можно отметить, что вычисление "левого нуля"
и "правого нуля", можно делать параллельно. Еще можно отметить, что нахождение первого нуля у нас уже 
реализовано - это BinarySearchFirst.

Кое-что проверил. Поиск первого действительно выполняется довольно быстро 2500 тиков. При этом, обращений к
функции глубины 12 (для других видов поиска - 27). Пытаюсь не обращать внимания на "чудо" в виде того, что
BinarySearchAll по-прежнему вне конкуренции - 1600 тиков, что не объяснимо. 

Продолжу мысль. Хочу заметить также, что теоретически, для выдачи всех решений, найдя первый нуль, мы можем
последовательно сканировать последовательность влево и вправо. Но будет ли это эффективнее - непонятно.
Если предположить, что чтение значения из файла является дорогостоящей операцией, то бинарные процессы 
нахождения границ и генерация значений промежутков (BinarySearchAll выдает поток entities, которые 
расположены подряд), наверняка будет более эффективно. Для поиска с одновременной выдачей, может оказаться
наоборот. Причем, возможно, двигаться "влево" является менее эффективным, чем двигаться "вправо".

Итак, нужна некоторая трансформация мотодов доступа к отсортированным последовательностям. Обозначим
PaEntity S - последовательность
long i - индекс последовательности
PaEntity e - вход в элемент последовательности, Get(e) - объектное представление элемента
Func<PaEntity, int> Depth - функция "глубины", Depth(e) < 0 - "левые" значения, 
	Depth(e) > 0 - "правые" значения, Depth(e) = 0 - искомые значения. Предполагается, что функция глубины
	согласована с функцией произведенной сортировки, т.е. она неубывающая на данной последовательности.

PaEntry S.BinarySearchFirst(Func<PaEntity, int> depth) - находит (любой) вход, глубина которого 0. Если вход
	не найден, результат e.IsEmpty.
static PaEntry BinarySearchFirst(PaEntry from, long number, Func<PaEntity, int> depth) - находит (любой) вход, 
	глубина которого 0 в диапазоне от элемента from c количеством number. Предполагается (надо проверять 
	внешним образом), что depth(empty) < 0.

Поиск в диапазоне int start, number выполняется следующим образом: 
PaEntry probe = S.Element(start);
int d = Depth(probe);
PaEntry result = d < 0 ? PaEntry.BinarySearchFirst(probe, number, Depth) : (d == 0 ? probe : PaEntry.Empty);

Для ряда процессов, нужен метод получения индекса элемента по его входу
long S.IndexOf(e);

Получив первую "нулевую" точку, часто нужно выявить диапазон всех "нулевых" элементов. Это можно сделать
с помощью статических методов
static PaEntry BinarySearchLeft(PaEntry from, long number, Func<PaEntity, int> depth) 
static PaEntry BinarySearchRight(PaEntry from, long number, Func<PaEntity, int> depth) 
Оба ищут в диапазоне от элемента from вправо на number элементов. Причем первый ищет самый левый элемент,
удовлетворяющий условию, правый - первый, не удовлетворяющий условию. Для левого метода предполагается, что
справа от диапазона.

Вроде все сделал аккуратно, результат 6000-10000 тиков. Это на домашнем компьюетере и на 1 млн. данных.
Как-то это все странно...
Похоже, есть ошибка. Характеристики расчета: индекс 291400 к-во 235 counter 28
Должны быть результаты: 291639 209 27
Итак, я "ушел назад" на 239!
Исправил одну ошибку. Теперь получилось 291640 - больше всего на 1 индекс, но к-во 235...

235 - 209 = 26

Вторую ошибку также исправил. Как всегда, при исправлении скопированного текста метода, не все исправил.

Затрачиваемое на вычисление диапазона время 6300 тиков. Не так плохо, но я ожидал лучшего...

Запустил тесты на рабочей машине, 10 млн. триплетов (1_1, 1, Berlin1, 2, berlin3, 3, 5, berlin6, 6):
15, 93, 86, 15, 35951, 493, 45835, 37747, 2494
15, 89, 85, 1, 360, 462, 1925, 2872, 2442

Класс DiapasonScanner
- Содержит ячейку PaCell 
- long i_current - индекс последней прочитанной ячейки, если конец файла, то -1
- Key key_current - значение последнего прочитанного ключа, если конец файла, то несущественно
- long number - количество элементов от предыдущего i_current до текущего или до конца файла
- keyFunction - функция ключа по Entry записи в ячейки
- Scan() - метод, сканирующий элементы ячейки от текущего до следующего не равного или до конца файла

     
Результаты тестирования

Со старыми методами:

17
1 52 мс.
0
2 1
219
3 135
8 
5 379
303
6 484

т.е.: 52, 1, 135, 379, 484

Расчет с использованием EntitiesMemoryHashTable (рабочий компьютер)
20, 0, 30, 60, 80

Рабочий компьютер, 10 М. триплетов
Загрузка 187 сек., объем базы данных 863 Мб., Пиковая нагрузка на оперативную память 170 Мб. Типовой процент использования
процессора - 13%. 





Первый запуск
97
1 80мс
0
2 0
1486
3 230
64
5 620
3109
6 840
   
Второй запуск
80 0 220 620 830
Исправлено чуть-чуть
80 0 223 586 770
с порогом = 10 для бинарного поиска по обратным и данным
91 0 250 707 1079
с порогом = 200 для бинарного поиска по обратным и данным
88 0 229 616 850

Попробую сгенерировать нужное количество параметров так, чтобы запросы не повторялись, но чтобы
запросов было много (500?). Попробую воспользоваться 6-м запросом, в нем можно получить множество
идентификаторов продуктов. 

Сообразил, что сейчас я не смогу этого сделать, поскольку строки кодирую без функции декодирования.

Придется это делать при вводе данных. Буду собирать триплеты вида ?s a bsbm:Product.


Пропуск 5-го запроса (143 раз) : 49 сек.
Есть небольшие отличия в количестве получаемых результатов: Virtuoso в конце дает 104, 196, 32, 267 строчек результатов.
TrueRdfViewer дает 100, 196, 32, 267

И все-таки, моя система проигрывает в 10 раз! Почему? Возможно, из-за наложения идентификаторов, имеющих один код.
При сокращении длины запроса, положение выравнивается. 
V - 17 сек.
T - 27 сек. 
А если еще короче?
Для 3-х строчек, получается V - 7.7, T - 1.8
Для 4-х строчек, получается V - 17.7, T - 28 - Вот где причина! 200 мс. 
На вычисления spD в среднем, это 5 тыс. внутренних вычислений

Для второго запроса, ситуация более благоприятная По полному запросу: V - 1.1, T - 0.4
Для этого благоприятного случая, среднее сисло вариантов 25. В них есть одно новое вычисление spD.
Всего получается 25 * 143 = 3000+ внутренних вычислений, время затрачиваемое на эти вычисления 100 мс. (всего - 140 мс.)
Что в общем, согласуется с 200 мс. на 5 тыс. ...
А можно ли ускорить эти 200 на 5000? Надо посмотреть код.

Пропуск пятого запроса теперь выполняется 34 сек. Не очень, но уже лучше. Не знаю, за счет чего...

По пятому запросу - тупик. Почти как пятый пункт анкеты... Если хочется конкурировать с Виртуозой, надо
этот тупик преодолеть. Все проверил и перепроверил. В рамках данной схемы, похоже лучше обрабатывать 
не получается. Корень проблемы - скорость получения результатов по запросам типа spD, наверное и по другим
также. У меня приблизительная цифра получается 200 мс. на 5000 выполнений spD с разными аргументами. 
Так что надо улучшить всего в 10 раз... Я придумал развитие существующей схемы обработки. Собственно я 
этот вариант уже реализовывал. В FSRDF. Надо модифицировать представление "широкой" таблицы, она станет
еще более широкой. Кроме тех полей, которые там уже имеются, а может, и вместо тех полей, надо записать
последовательность имеющихся в соответствующем направлении предикатов, снабженных диапазонами значений
искомого в соответствующих таблицах.   

Итак, новая широкая таблица (GroupedEntities) может выглядеть следующим образом:
GETable = [entity: integer, subjInOTriples: DiapLinks, objInOTriples: DiapLinks, subjInDTriples: DiapLinks];
DiapLinks = {all: Diapason, predList: [pred: integer, diap:Diapason]};
Diapason = {start: longinteger, number: longinteger};

Видимо, эта структура должна быть PxCell. Посмотрю код.

Тестирую GroupedEntities, тест на 1 млн.
количество сущногстей 151704 - похоже на правду...

Вроде получается. Создание хеш-словаря выполняется за 2 сек. Можно пока попробовать поработать со словарем.
Правда для 1 млн. захватывается 167 Мб. оперативной памяти, но сейчас это не так важно. Важно, провести
эксперименты с 10 млн.

Буду отлаживаться с параллельно работающим старым решением и формирующимся новым.
Загрузка "всего" заняла 47 сек.

2-й запрос выполняется за 1229 мс., последние количества вариантов:
20, 25, 23, 22, 20, 21, 24, 18, 16

Поскольку, предположительно, заметнее результат модернизации будет заметен на 5-м запросе, перехожу на него.
Результат достигнут за 25.9 сек. послидние количества:
7, 8, 32, 9, 19, 48, 91, 16, 1, 25

Вроде получается! Я подправил только spD, но уже получился выигрыш, теперь время 9.4 сек!!! Но надо продолжать
дальше.

Получаться то получается, но опять "вылезла" старая проблема с ElementValues. Не знаю как ее устранить.
Пока попробую обойтись без нее. 

Вроде разобрался. Улучшить результаты не получилось, но итак прогресс довольно хороший. Попробую провести
расчеты на рабочем компьютере.

На рабочем компьютере построил тест на 10 млн. триплетов. Построение заняло 200 сек. Объем базы данных 1.12 Гб.
10 млн. не сработали, странно...

1 млн. работает (в 64-разрядной моде). 
5-й запрос выполнен за 3320 мс. Это в среднем 23 мс. на запрос.
2-й запрос выполнен стремительно - за 188 мс. Это в среднем 1.3 мс. (760 QpS)

старые тесты также работают. тесты 1, 2, 3, 5, 6 выполнились за:
 
40, 0, 20, 30, 50

Удалось пропустить 2-й запрос. Результаты получились оптимистичные:
202 мс. на все 143 (!) запроса (707 QpS)

26 сек. на 5-й запрос. В среднем 180 мс. 2.7 Гб. оперативной памяти! 1.12 дисковой памяти
Виртуозо выполняет 5-й запрос за 4.9 сек. Надо "поиграть" с запросами.

Первое "предложение" выполняется у меня практически мгновенно - 19 мс на все.
Виртуозо выполняет 140 мс. Это ничего не означает, возможно скорость трансляции.

Два первых выполняется у меня 400 мс. При этом, происходит сильное "размножение" результатов - в концовке,
к-во строчек результата - от 3 до 15 тыс. Возможно, среднее - 5000 или поболее. 
Виртуозо выполняе две строчки за 7.7 сек. 
Резко хуже выполняется 3 строчки. 12 сек. Тысячи даром не проходят...
Если переставить строчки, то мало что меняется. Итог 
Виртуозо - 5-6 сек., TrueRdfViewer - 18 сек. В три (с небольшим) раза. Уже не в 10!

20140311 08:09
Решил разобраться в том, почему что-то получается (2-й запрос), а что-то не получается (5-й запрос).

Идея заключается в определении мест, которые "жрут" время выполнения запросов. Беру 5-й запрос,
беру три первых предложения запроса. Третье - уже "жрет". 
Взял 4. После выполнения трех, суммарное время - 441 мс. После выполнения четырех (последнее - spD),
суммарное время - 2222 мс. Вполне ощутимая разница. 
Потом надо выделить идентификаторы и предикат, на которых выполняется spD. Можно записать коды сущностей 
в гибкую ячейку. Потом хорошо бы проверить число совпадающих запросов. Если оно велико, то надо думать
в другом направлении. Потом надо "чисто" выполнить только запросы на получение данных (в данном тесте -
чисел) по заданному множеству идентификаторов. 
Если на этом этапе время вычисления станет существенно меньше 1700 мс., надо разбираться почему.
Потом предполагается вычислить диапазоны или, по крайней мере, засечь время вычисления всех диапазонов.
Если, как предпологается, основная часть вычисления в запросе по получению потоков результатов по диапазонам,
то надо начать формировать новый план. 
Здесь есть ответвления, поэтому попробую пройтись по уже продуманному. 


predicate = 2134963467 
В Testsubjects.pac записано приблизительно 100 тыс. кодов сущностей.

Немножко по-другому, но я определил, что основное время тратится на получение значений по диапазонам.
Те самые 1700 мс. Тупик? Не знаю, попробую пооптимизировать данное место. 

Оппа-на! Неожиданность. Я оставил ... Показалось... Нет неожиданности.

Проверка выявила, что каждые 100 тыс. Get() в "случайном" порядке, добавляют 1 сек. времени. Ну может,
0.8 сек. И с этим я НИЧЕГО поделать не могу!..

Кстати, я не проверил, есть ли повторы, это важно.
А теперь, похоже, действительно сюрприз! Оказалось, что из 126 тыс. кодов сущностей, только 143 (!) являются
различными. У меня как раз 143 раза тест выполняется с различными параметрами. Может я где-то ошибся?
Надо смотреть запрос и, возможно, делать более тонкий анализ.

12:26
Ура, вроде получается. Сделал простой кеш внутри реализующих процедур типа spD, ...
Теперь тестовый фрагмент исполняется 540 мс. т.е. немногим дольше "базовых" 440. Возможно, это решение
не самое лучшее, но для получения предельных характеристик - приемлемое. Сделаю аналогичные изменения
для других процедур и потестирую 10 М данные на рабочем компьютере.

     

  








 

