
Решил сделать "чистенький" проект по работе с "правильным" RDF. Имеется ввиду типизация полей данных.
Если я правильно понимаю стандарт RDF, значения полей данных могут быть типизированы. То есть,
объектом подобной тройки будет константа вида:
... "значение"^^<объект типа>

Если этой части константы нет, то подразумевается стандартная строка с известным типовым узлом:

"value"^^xsd:string
или 
"value"^^<http://www.w3.org/2001/XMLSchema#string>
 
Будем поддерживать: 
xsd:integer

В дальнейшем, добавим:
xsd:date
xsd:dateTime
xsd:boolean или как он там называется
xsd:number или как-то по-другому (xsd:decimal, xsd:double!) 
 
Другие типы можно будет добавлять по мере необходимости.

Теперь о языковой специализации. Если я правильно понимаю логику RDF, при его применении, фиксируется то же
значение типа, что и без указаний типа и специализатора - xsd:string.
И только в этом случае, этот специлизатор (@ru) может возникнуть. Почитаю стандарт. 

Почитал. Что-то там не сходится. Получается, что просто константная строка не сравнима с типизованной строкой,
так же как и строкой с языковым специализатором. В Turtle строка и типизованная строка идентичны. Я пойду дальше.
У меня будет храниться объединение:
RLiteral = 
	integer^integer,
	string^{s: sstring, l: sstring},
	date^longinteger,
	...

Ввод данных буду производить с помощью упрощенного парсера ttl.

Сначала отладил программу на стандартных данных. Построение базового портрета занимает на домашнем компьютере
23 мс. для 10 (стандартных) идентификаторов и это после разгона. Попробую загрузить берлинский миллион.

Загрузил. На берлинском миллионе, базовый портрет получается в первый раз за 2350 мс. Пять следующих 
портретов вычислены за 7 сек. При повторном запуске, результаты - лучше. Первый портрет - 42 мс., пять
следующих - 23 мс. База данных - 247 Мб. Загрузка данных и индексация производилась 40 сек. (15 сек. - загрузка).

Следующая задача, которую хочется решить - это гибкое управление сортировкой-выборкой. Я имею ввиду то, что
хотелось бы отсортировать индексы первично по субъекту (или объекту, соответственно) и вторично - по предикату.
Тогда можно будет производить выборки и по одному заданному субъекту и по паре субъект-предикат. Вроде ничто не
мешает. Посмотрю код.

Посмотрел, сделал. Загрузка в сортировкой по парам субъект-предикат и объект-предикат выполняется за 111 сек.
Построение портретов вроде работает. Пять портретов делаются за 25 мс. Теперь сделаю нужные процедуры.

Решил, что двойной сортировки недостаточно и теперь "главный" индекс объектных триплетов вычисляется по сортировке 
субъект-предикат-объект. Время загрузки почему-то уменьшилось. 
68 сек. загрузка.
Теперь появляются осмысленные результаты, потом надо будет их сравнить с вычисленными через Sparql.

57, 65, 213, 60, 53, 51  время=538

476 сек.
30 мс., 50 мс. - 6 прогонов первого теста.

20140212 04:29
Решил поработать. Сделал удобный вариант теста. Это 1 млн. берлинских триплетов. Это первый берлинский запрос
и это некоторая заметрая разница между тем, что получается и что можно было бы ожидать. Тестирование на
домашнем компьютере дает 26-30 мс. для выполнения 6 запросов с различными стартовыми точками (идентификаторами).
Это при фиксации только первого предложения Sparql-запроса. Использование фильтрующего второго - дает уже
515-528 мс., третьего - 685 мс. Добавление вычисления поля добавляет совсем не много - 700 мс. 
Если убрать фильтры, получится 540 мс. Но там заметно больше (раза в 4) веточек, которые ранее убирались 
фильтрацией. 

Задача номер 1 - сделать фильтрацию типа проверки существования триплета (существенно) более эффективной.

Этап 1.
Завожу массив битовых пар в виде массива целых чисел. Число битовых пар N_bpairs. Его надо будет вычислить.
Но пока его положу 8 М, т.е. число битов 16 М, число целых 0.5 M, что равно 524288, что соответствует 2**19.
Избыточность такой шкалы - 8, надеюсь этого хватит. Индекс массива битовых пар будет 2**23
Далее, для объектных триплетов вычисляю индекс как Hash(subject) xor Hash(predicate) xor Hash(object) и
оставляю в числе 23 бита. Операция xor в Си выражается символом ^. 
Полученным индексом я выбираю два бита (arr[ind >> 4] >> ((ind & 15) << 1)) & 3;
Два бита кодируют "попадание" триплета в данный код. 
0 - нет "попадания"
1 - есть единичное попадание
2 - есть несколько попаданий

Запись двухбитного кода в шкалу по индексу осуществляется оператором
arr[ind >> 4] = arr[ind >> 4] & (~(3 << ((ind & 15) << 1))) | ((value & 3) << ((ind & 15) << 1));
где v - записываемый код.

Наверное, надо оформить шкалу классом. Попробую.
Некоторый код написал. Пока шкала формируется "динамически" - в оперативной памяти и передпропуском тестов.
после "разгона", шкала вычисляется 1187 мс.
Сделаю проверку шкалы.

Проверка показала достаточно логичные результаты. Для нашего миллиона триплетов, 8 млн. позиций - пустые,
327 тыс. - единичные, 58 тыс - двойные. Ошибочных кодов нет.

Вроде получилось. Время выполнения 6 запросов - 306 мс. Но там есть "неудачный" (мало фильтрует), он 
среднее время несколько увеличивает. 

Теперь настало время проверить идею с формирование Linq-запросов, похожих на Sparql. Идея вырисовывается
следующей:
Для RDF-движка определяем методы, похожие на триплеты. 
IEnumerable<RPack> spo(this.IEnumerable<RPack> pack, object s, object p, object o);
Другие методы имеют такой же интерфейс (!) и называются аналогично: Spo, spO, Spd и т.д.
Причем большая буква символизирует то, что соответствующий параметр является "приемником" 
вычисляемых значений. Если эта буква маленькая, то это уже вычисленное значение или константа. 
Параметры s, p, o могут быть либо целым значением, либо строкой. В первом случае, это означает
индекс массива, где находится строка, соответствующая этому значению. Во втором случае, строковая
константа является собственно значением Entity. Для данных (d) множестов типов расширяется на
возможные типы данных: строки, целые, вещественные, даты, логические и т.д. В случае, когда
параметр помечен большой буквой, допустимо только целое значение индекса массива, куда будет 
записано то, что вычислено.    
Рассмотрим эти методы несколько подробнее. 
spo является фильтром. Этот метод определяет есть ли в хранилище объектный триплет с соответствующими
значениями субъекта, предиката и объекта и если есть, значение pack пропускается. Остальные варианты -
отбраковываются. Если есть неопределенное значение, то его надо определять. Соответственно, по известным
частям триплета порождается множество вариантов, которые "запускаются в оборот". 
Фильтр - это фильтр вариантов, задающий предикат фильтрации. Опция - дополнительная настройка над
потоком вариантов, размещающия неопределенным значением какую-то часть переменных и далее, вычисляющая 
или не вычисляющая эти значения. 
Объединение - некоторый разветвитель, обеспечивающий выполнение дизъюнкции наборов вариантов.

Попробую, что-ли...

Попробовал, получилось! Есть еще недоделки, но код вида:

                string bsbm = "http://www4.wiwiss.fu-berlin.de/bizer/bsbm/v01/vocabulary/";
                string bsbm_inst = "http://www4.wiwiss.fu-berlin.de/bizer/bsbm/v01/instances/";
                // query 1
                object[] row = new object[3];
                int _produc = 0, _value1 = 1, _label = 2;
                var quer = Enumerable.Repeat<RPack>(new RPack(row, ts), 1)
                    .Spo(_produc, bsbm + "productFeature", bsbm_inst + "ProductFeature19")
                    .spo(_produc, bsbm + "productFeature", bsbm_inst + "ProductFeature8")
                    .spo(_produc, "http://www.w3.org/1999/02/22-rdf-syntax-ns#type", bsbm_inst + "ProductType1")
                    .spD(_produc, bsbm + "productPropertyNumeric1", _value1)
                    ;

вполне похож на Sparql-прототип. И вполне легко формируется на основе прототипа. При этом, исполняется на
домашнем компьютере (на 1 млн.) за 61 мс.
 
Я несколько приостановился на типах данных (литералов). В принципе, в разделе Triple определен класс Literal,
которым надо пользоваться в этих местах. Соответственно, для spD аргумент данных должен быть оформлен следующим
образом: либо это целый индекс, либо значение класса Literal. В массиве хранения данных row, позиция значения
переменной поля будет занимать значение типа Literal. Надо сначала вернуться к вводу данных и задействовать 
тип, если он указан.

Первый тест удалось выполнить полностью. Результаты совпали. Надо сделать некоторые другие тесты.

Сделал тесты 1, 2, 3, 6
Результаты прогона на домашнем компьютере тестов на 1 млн. дают следующие резвльтаты:
422, 66, 876, 1801
Не очень, но это измерения.
83, 2, 270, 1167 - второй прогон

20140217 10:50
Я сделал довольно принципиальную ошибку. Это касается использования шкалы для проверки существования конкретного
(объектного) триплета. Я посчитал, что выгодно шкалу коидровать двумя битами с кодами 0 - нет триплета, 1 - есть один
триплет с данным кодом, 2 - есть больше одного триплета с данным кодом. Однако, данная логика в вопросах проверки
не сработала. Дело в том, что проверяться может любое сочетание субъект-предикат-объект. И код этого сочетания может 
совпасть с кодом одиночного триплета, имеющего значение 1. В итоге, при проверке, я выдаю, что этот триплет существует,
а на самом деле - нет. 

Переделывать шкалу - требует времени. Я пока оставлю двухбитный вариант, просто подправлю его использование.

Вроде заработала новая версия, наверное - "задышала". Испытываю на 1 млн.
Загрузка 23 сек.
Первое исполнение теста 151, 1, 280, 981
Второе - столько же.
После перезагрузки 10163, 122, 10979, 13284 - забавно...
Загрузка 18 сек. Объем базы данных 70 Мб.

Загрузил 10 млн. время 335 сек.
Времена: 1066, 617 (частичный 1_1), 2225, 12133 мс.

Снова реализую и внедряю шкалу. Сначала шкала создается динамически и проверяется ее работоспособность.
На 1 млн., 81 тыс. - разнича между числом триплетов и числом точек на шкале. Это около 20 %

Времена без шкалы: (количества результатов 51, 0, 219, 303)
68, 0, 112, 376
Со шкалой
1 - полный отказ 
9 - работа со шкалой (56 результатов)
83 - работа без шкалы (56 результатов)
1 - без фильтрации (223 результатов)
29 - без шкалы (56 результатов)


Загрузка данных в 10 млн. триплетов. Время загрузки - 144 сек., Объем данных - 688 Мб.
Времена исполнения запросов:
241, 1, 868, 4507 мс.
238, 1, 844, 4479

  
Перенес систему на рабочую машину. Загрузка 1 млн. длится 12 сек. Объем базы данных 84 Мб.
Времена прогона тестов:
30, 15, 62, 255, 221 мс.

10 млн.
Загрузка 174 сек. ОБъем базы данных 823 Мб.
Времена:
120, 111, 448, 2701, 2442


Пришла в голову группа идей по поводу возможностей ускорения выполнения запроса. Есть разные вариации
этих идей. Одна из вариаций довольно проста в реализации. Надо попробовать отсортировать множество
триплетов otriples. Элементы этого множества - записи фиксированного размера, поэтому сортировка возможна.
Для начала, такая сортировка ничему не помешает. Но теперь это множество можно будет использовать
вместо индекса для тех же целей. То есть, задавая s или s-p или s-p-o, можно получать нужные подмножества.
Попробую.

141, 1, 280, 1004
96, 2, 248, 1023

Вроде выигрыш есть. Посмотрю пристальнее и детальнее.

На запросе 1_1 время выполнения ведет себя следующим образом:
3, 32, 37, 58, 58, 76 - в зависимости от этажности запроса
3, 61, 76, 97, 95, 114

Выигрыш явно есть. Теперь добавлю шкалу.
3, 11, 18, 38, 38, 57
- также выигрыш явно есть

Теперь попробую изменить другие места, использующие spo-индекс
Сейчас буду заниматься серьезными оптимизационными работами. Надо записать текущий результат (тест - к-во - время)
1 51 81
1_1 55 58
3 219 259
5 8 1233
6 303 1055

После того, как я прооптимизировал работу с otriples, получились результаты (последняя колонка):
83, 56, 243, 1158, 1006

По крайней мере, не хуже.

Теперь внимательнее посмотрю на исполнение второго теста (1_1).

После трех стадий - 16-17 мс. А было - 18. Не хуже. Добавление четвертой стадии доводит до 37 мс., 
т.е. добавляется 20 мс.

Надо работать с dtriples.

Похоже, что-то получилось. Результаты прогона тестов:
60, 37, 150, 636, 549 Ура! Раза в 2 в ряде случаев время сократилось.

<<<<<<< HEAD
Решил разобраться с теми тестами, где результаты хуже, чем у Виртуозы. Начал с третьего теста. Первая 
часть запроса выполняется хорошо, за 2 мс. и получается 220 результатов. но потом, на выполнение 220 .spD
затрачивается 42 мс. 
Получается, что выполнение одного .spD "тянет" на 5 spD за миллисекунду.

Еще один резерв. Переставление в пятом запросе третьего оператора в конец, сокращает время вычслений
с 610 мс. до 430.

Пришла в голову любопытная идея. У нас есть переменные, которые накапливаются в по мере вычисления.
Сейчас эта переменная - достаточно простая. Для Entity это объект, содаержащий строку или целое (в случае
целочисленного кодирования). А если переменную Entity усложнить? Скажем, добавить пару-тройку полей диапазона
уже произведенного поиска. Так сказать, имитация объектного представления. Первое вычисление переменной видимо
ничего кроме значения не привносит. Но если переменная использовалась в операторе spO, то поместить в нее
дополнительное значение диапазона s*O. Ну и так далее. Тогда (следующее) вычисление spO можно будет вычислить
внутри имеющегося диапазона.

Посмотрю насколько сложно реализовать эту идею.

В общем, мне идея нравится. Практически создается вариант объектного представления. Можно идею развивать 
и дальше, напр. в сторону присутствия объектной информации везде, где мы выходим на объект. Например,
в представлении otriples_spo, можно было бы для каждого o иметь диапазоны прямых и обратных таблиц.

Некоторое изменение схемы Linq-реализации Sparql заключается в том, что теперь и для константных значений
Entity нужны позиции в массиве вычисляемых значений. Кроме того, диапазон может быть пустым, это также надо 
иметь ввиду. 

Итак, попробую написать класс ObjectRowInt в отделаьном модуле.

15 мс. - время 10 вычислений ts.GetSubjectByObjPred(obj, pred).Count();
5 мс. - время 10 вычислений диапазона
17 мс. - 10 раз диапазон + в диапазоне. 

Ура! Разобрался с некоторыми особенностями работы с применяемыми структурами. Пришлось даже сделать изменения 
в ядре. Но теперь я с оптимизмом гляжу в будущее и есть множество мест, где возможны улучшения.

Два триплета в тесте Berlin1 (это перерабатываемый первый тест) выполняются 15 мс. Третий, добавляет до 21 мс.
Попробую модифицировать нужным образом метод _spo.

Вроде модифицировал. Теперь три части запроса срабатывают за 14-15 мс. А две - за 11-12. 

Преодолел некоторые трудности. Теперь первый тест работает. И выполняется за 43 мс. Это вместо 60, которые 
были ранее.      

После перезагрузки, времена следующие (1_1, Berlin1, 1, 2, 3, 5, 6) (Berlin1 и 1 усечены до одной строки):
23, 9, 2, 88, 4340, 2151, 2317 
20, 7, 2, 5, 153, 439, 544

Бинарный поиск 2600-2700 тиков
Вычисление диапазона 6700-7300 ticks
Функция глубины - одинаковая
Добился, чтобы диапазон вычислялся как бинарный поиск. Можно двигаться дальше. 2700-2900 тиков.

Увы... Поторопился рапортовать. Правильное измерение показало 7300-8000 тиков. Я не понимаю причину!!!

Надо считать число чтений из файла. Как это сделать?

Можно через функцию ElementDepth. Попробую.

Попробовал. На данном тесте число обращений к функции глубины - 27. Очень мало и совпадает с таким же числом
для бинарного поиска. Я еще меньше понимаю разницу в эту сторону имея ввиду то, что бинарный поиск генерирует все
209 входов PaEntry. Это не сопровождается чтением данных, но сами структуры формируются. И их гораздо больше, 
чем в случае вычисления диапазона (раз в 10). Попробую поискать данные, где в диапазон попадает больше значений.

Нашел, это тип bsbm:Product у него 2848 элементов в диапазоне. Время 8476, число обращении к глубине 34.
теперь бинарный поиск дает 4700-5177, счетчик обращений к глубине - 34.
Для случайного entity, не попадающего в какой-то идентификатор, получается время 4600 тиков.
Для бинарного поиска - 2400.

Поскольку я не знаю что делать, попробую "покрутить" систему на рабочем компьютере и с большими данными.






Загрузка 10 млн. длилась 174 сек. 
Поиск всех с отсутствующим входом длился 2207 тиков. Повторно 2036. Число доступов к файлу 22.
И здесь также вычисление диапазона выполняется дольше 3800-3824.

Большой тест: диапазон 6400-6500 тиков, поиск 24500 тиков. Найдено 28480 вариантов
Проверил еще раз, действительно вычисление диапазона работает быстрее 6400 тиков, диапазон
также содержит 28480 вариантов! На тесте 1: диапазон 6700 тиков, поиск 4000 тиков, найдено 1441 вариант, 35 "глубин"

Фиксирую результаты прогона тестов на 10 млн (b1, 1, 2, 3, 5, 6).
90, 94, 495, 0, 1935, 2524

Займусь пятым тестом, там должен быть выигрыш от новой схемы интерпретации.

Сделал по-новому 3-й и 6-й тесты: тестрование (b1, 1, 2, b3, 3, 5, b6, 6):
80, 100, 0, 380, 470, 1990, 2950, 2560
88, 92, 0, 377, 457, 1943, 2918, 2413

475-530 тиков.

Происходят некоторые "чудеса", которые я не в силах объяснить. Долго пытался выявить принципиальное различие
в методах BinarySearchAll и BinarySearchDiapason. Кроме того, что бинарный поиск элементов активно использует
циклы и оператор yield return, я ничего существенного не нашел. Сделал рекурсивную процедуру сканирования,
работающую по логике определения диапазона. Фактически, делаются только замер глубины среднего значения и уход 
в рекурсию. Результаты стали похожими на бинарный поиск. Потом взял бинарный поиск и перенес в другое место кода
и переименовал. Думал начну "чистить" и получать "чистый" сканер. Неожиданностью явилось то, что он стал резко
медленнее работать. Было 2600-2700 тиков, стало 20000 тиков. Что же произошло? Поищу.

Похоже, это какие-то особенности исполнительской системы. Или трансляции. Я сециально сделал точную копию 
трех статических методов BinarySearchInside/Left/Right и только переименовал методы. А потом стал присоединять 
методы к разным "пускачам" и смотреть что получится. Получается нечто странное. Штатно, метод бинарного
поиска работает 2600-2700 тиков (Неплохо!). Но иногда либо он, либо эквивалентный ему BinarySearchScan,
дает или 4000 тиков или 20 тыс. тиков. Непонятно...

  
 
   