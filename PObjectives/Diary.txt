
Замысел проекта заключается в том, чтобы попробовать реализовать примитивный подход к объектному представлению 
базы данных средствами PolarDB. Пусть есть множество объектов нескольких классов. Для примера, пусть у нас будет класс
персон и класс городов. А между ними - отношение "проживает". Мы хотим работать с объектами классов
Person и City причем так, что все хранится в базе данных. 

В качестве начальной базы данных, создадим две последовательности вида:
Person = [id: string, name: string, age: int, live: id];
City = [id: string, name: string]

Понятно, что id может быть скрытым полем, что id может быть кодом какого-то вида. Менее очевидно, что для City есть 
скрытое поле - последовательность персон, проживающих в данном городе. Совсем не очевидны вопросы индексирования. 

Таким образом, C# классы Person и City выглядят следующим образом: 
class Person
{
  string name;
  int age;
  City live;
}
class City
{
  string name;
  Person[] live;
}
У полей этих классов можно и нужно определить свойства Get, Set. Должен быть конструктор, возможно, деструктор.

Соответственно, когда мы имеем переменную класса Person, понятны варианты действий:
Person p = new Person();
p.name = "Иванов";
p.age = 33;
City c = p.live;

Как это реализуется. В экземплярах класса Person, как и в экземплярах других классов, реально хранится только 
служебный код. Возможно, это id. Но это может быть и значение класса PaCell. Допустим второе.
Тогда чтение поля p.name будет чем-то вроде (string)ent(p).Field(1).Get(). Простая изолированная функция, 
способная участвовать в выражениях.
p.age = 34;        
как ни странно, можно реализовать просто, пользуясь атомарностью поля:
ent(p).Field(2).Set(34);

В других случаях, это не проходит. При реализации 
p.name = "Петров";
Надо создавать другую запись, а данную уничтожать. 
Теперь что означает p.live в контексте чтения. В принципе, речь идет о чтении хранимого идентификатора, обращение
с этим идентификатором к таблице Cities и получение кода или указателя города. Обратное действие сложнее. Если для 
конкретного города мы хотим получить множество проживающих персон, надо "сканировать" таблицу персон и выявлять нужные. 
Если таблица персон имеет индекс, связанный с кодом города, такое сканирование можно заменить бинарным поиском. 
Тонкость заключается в том, что мы не собираемся формировать реальное множество, нам хватит итератора. Можно говорить о 
Linq-формуле. 

Менее очевидными являются вопросы поиска значения или подмножества значений во множестве объектов заданного типа. 
Тут даже языкового варианта не находится. Наиболее естественны выглядит решение, когда нужные множества есть как
IEnumerable или IQueryable и от них можно начинать Linq-вычисления.
Напр. есть переменная 
personSet
от которой можно начать Where, Select и т.д.
Соответственно, new Person() неявно добавляет члена в коллекцию, p.Remove() - убавляет. 

Технически, можно сделать статическую переменную в классе Person, может метод будет называться All, может по-другому. 

Есть еще важные вопросы. Например, как быть, когда запись не уничтожается, а модифицируется. На нее могут быть установлены
разные ссылки. 

Надо "переварить" то, что написал и обдумывал. А в принципе, можно уже где-то начинать кодирование. 

20140313 22:01
Попробую написать некоторую реализацию замысла. Сразу буду ориентироваться на редактирование данных.
Для этого, мне понадобится FlexIndex. Логика построения гибкого индекса следующая. Он существует при
простой последовательности свободного формата. Причем элементы последовательности - записи с первым
полем deleted. Семантика поля в том, что логически, последовательность представляет собой множество
записей в которых deleted установлен в false. Добавления к последовательности производятся стандартным
AppendElement(), убавление - установкой поля deleted. При опорной последовательности может существовать
произвольное количество "гибких" индексов. Индекс создается при существующей (возможно нулевой) 
последовательности и постоянно синхронен с последовательностью если при каждом добавлении элемента
через AppendElement, ссылку на добавленную запись добавлять в индекс методом AppendEntry(). Синхронизация
по убавлению элементов осуществляется автоматически.  
Индекс строится по некоторой, в общем случае виртуальной, колонке опорной последовательности через задаваемую на
элементах последовательности функцию KeyProducer. И по значениям этой "колонки" индекс как бы сортируется.
Это добавляет к последовательности следующую функциональность - можно получать указатель на первую запись или
поток указателей на все записи, удовлетворяющие либо совпадению ключа с образцом, либо нулевому уровню т.н.
глубины, вычисляемой на значениях элементов последовательности. Определитель глубины задается
функцией elementDepth, вычисляемой на элементах записи. Функция глубины должна быть согласованной с порождающей
индекс функцией KeyProducer.

Как должно выглядеть объектное построение? Исходным представляется понятие коллекции элементов определенного
класса. Т.е. элемент без коллекции не существует. Можно этот факт "замаскировать" если коллекция элементов
одного класса только одна. Но, в общем случае, collection.NewElement() порождает новый элемент именно в
этой коллекции. Обратным действием является collection.RemoveElement(element). Также, для уничтожения
определен прямой метод element.Remove(). Как работать с элементами (коллекций), уже обсуждалось, теперь
рассмотрим работу собственно с коллекциями. Главное действие - получение по идентификатору элемента его 
экземпляра. Экземпляр элемента представлен в подходе минимально - его указателем PaEntry, и, наверное,
некоторой дополнительной информацией, которая сейчас неясна. Соответственно, у коллекции всегда есть
индекс по полю идентификатора. Другие индексы создаются по потребности. 
Элемент коллекции представляет собой запись. Два поля записи - скрытые. Поле deleted и поле id. Пусть 
они будут первым и вторым в записи. Другие поля имеют отображение (Mapping) на свойства C# класса, 
сопоставляемого с типом элементов коллекции. Кроме реальных полей элементов последовательности, 
могут существовать виртуальные поля. Виртуальное поле - это когда в C# классе поле есть, а в структуре записи
- нет, но есть функция отображения "элемент коллекции" -> значения поля класса. Формирование и индексацию
виртуальных полей рассмотрим позже. 
Поле, содержащее измеримые значения, может быть индексировано. И по этому полю можно производить поиск типа:
collection.Elements().First(предикат) или .Where(предикат) и др. аналогичные.

Но детали могут потребовать не такой простой методики трансляции Linq-выражений.

Коментарии к классу PObjectiveCollection
Мы будем реальный задаваемый тип элемента eType погружать в расширенный тип элемента (Extended Element Type)
такой, что eeType является записью с двумя предопределенными колонками deleted и id. А третья колонка имеет 
eType. Альтернативным решением было бы наложить услвия на внешнее определение типа, так я таже делал.

В качестве типа (ключевого) идентификатора принимаем целое. Значение идентификатора - номер созданного 
элемента коллекции, начиная с 0. Коллекция хранит номер очередного идентификатора idNew. Но это хранение является 
явным только для объектного представления - экземпляра класса PObjectiveCollection. Во внешних данных,
хранение idNew является неявным. Его можно определить по последней добавленной записи в опорную 
последовательность. Однако, в силу свободного формата ячейки хранения, выйти на эту запись не так просто.
Если последовательность не подвергалась чистке, т.е. уничтожению deleted элементов, то idNew совпадает с длиной
последовательности. На последний элемент можно выйти через базовый индекс по ключевому идентификатору. Надо 
взять последний элемент малой индексной таблицы, а если ее нет, то последний элемент большой. При таком подходе,
при создании индексной таблицы, ее можно не сортировать. Вычисление idNew видимо потребует добавления к 
FlexIndex.

Также скорее всего, понадобится счетчик counter. Для существующей коллекции, это количество элементов минус количество 
уничтоженных элементов.

Формирование idNew и counter можно совместить с сканированием последовательности при разогреве (warmup) базы данных.

Принимаются решения: idNew совпадает с количеством элементов, пока мы не займемся чисткой мусора в коллекции.
По counter'у - при первом обращении, производится вычисление сканированием, далее, counter отслеживается
при эволюции коллекции. Неинициированное значение counter'а = -1.

Корректирую терминологию и код. Теперь (ключевой) идентификатор опорной последовательности будем называть 
ключем (key). 

Теперь, для продолжения, надо разработать семантику класса PObjectiveElement. Предполагается, что именно этот
класс будет наследоваться и доопределяться и он является главным участником обработки на C#.

Суть класса - задать форму вложения и функциональность для элементов коллекции. По коллекции, можно порождать
новые элементы, можно уничтожать элементы, можно находить по коду. Можно также сканировать элементы коллекции.
Пока достаточно. Экземпляры класса PObjectiveElement должны содержать ссылку на коллекцию и, главное -
поляровскую ссылку (PaEntry) на элемент опорной последовательности коллекции. Для начала, достаточно. Напишу
начало кода.

Написал. Определил поля и конструктор. Конструктор надо "спрятать" пусть он будет internal. Возвращаюсь к коллекции.

Работаю над NewElement. Поскольку "пустой" новый элемент редко будет иметь смысл, этот метод всегда предполагается
со значением, которое и сформирует новый элемент. Значение - объектное поляровское представление структуры eType.

Сделал. Уже пора кое-что испытывать. Теперь сделаю для коллекции простые методы: Elements() и ElementValues(). А
для объектного элемента - метод Get().

Теперь попробую испытать сделанное. Заведу коллекцию персон. Добавлю в нее несколько и посмотрю что там накопилось. 

20140315 07:52
Испытания прошлый раз прошли успешно, но пока я мало что сделал. 
Продумывание получающейся конструкции, дает основание полагать, что нужен еще один уровень группирования - назовем
его "база данных". Итак, база данных состоит из коллекций, коллекции состоят из элементов различных типов.
В элементе есть ссылка на содержащую его коллекцию. В коллекции есть ссылка на охватывающую базу данных. В
базе данных можно явно запросить коллекцию по ее имени (наверное, идентификатору). В коллекции можно запрашивать
элементы по ключу. Получается конструкция типа MongoDB, только там базы данных называются namespaces. Отличие
нашего решения в том, что в MongoDB это единственный вариант устройства базы данных, у нас - один из довольно 
большого количества вариантов. 

Итак, создаю класс PObjectiveDatabase и прописываю все варианты переходов от одних структур к другим.

18:01
Ну так, более или менее начинает работать. Пока нет схемы обновления индексов, но это мелочи. С коллекциями и 
базами данных все не слишком сложно - базовые классы годятся на почти все случаи. Для коллекций есть некоторая 
специлизация через тип записи. Пока это не "напрягает". Но далее, элементы последоватлеьностей хочется снабдить
C# классом, наследником PObjectiveElement, но обладающим, как минимум некоторыми (полезными) свойствами (properties).
Пока не знаю как это делать. Попробую через параметризацию типом. Как-то так еще не приходилось делать. 

20140316 20:56
Я вчера застрял на придумывании схемы определения базовых классов системы. Как-то плохо получается. Вся эта 
параметризация мне нужна для реализации классов, являющихся расширением PObjectiveElement. Суть проблемы
заключается в том, что в непараметризованном классе PObjectiveCollection нужно иметь возможность выдачи
элементов класса-наследника PObjectiveElement. При этом, в классе-наследнике могут быть поля и свойства, которых
нет в родительском. Возможно надо сделать конструктор, который по значению родительского класса создает дочерний
элемент. Возможно, не надо поддерживать добавляемые поля, т.е. не надо их допускать, обходиться свойствами. Хотя
вряд ли. Нам понадобятся и скалярный и верторный индексы. 

Проведу программный эксперимент.   

20140319 06:18
Проболел три дня, совсем не мог работать по причине неработоспособности головы. А бросил я работу на интересном месте.
Я как раз, наконец, придумал общую схему реализации параметризации. Я ее изложил в виде модуля Experiment. Он независимый,
носит иллюстративный характер. Теперь я даже пространство имен ему изменил, чтобы в рабочем варианте использовать
имена классов, методов и свойств. Суть решения в следующем. Базовой "осью" проходит непараметризованный вариант. 
База данных, коллекция, элемент - это главные участники. И для них определены базовые методы типа 
    class Collection
    {
        public IEnumerable<Element> Elements();
        public Element Element(int key);
    }
Но также там есть их эквиваленты для назначения специальный объектных представлений для элемента
    class Collection
    {
		...
        public TElement Element<TElement>(int key) where TElement : Element, new()
        {
            Element el = this.Element(key);
            var res = new TElement() { inCollection = el.inCollection, entry = el.entry };
            return res;
        }
    }
Главное, в этих определениях ограничения на тип-параметр. Ну и изложена некоторая схема реализации, которая должна 
сработать. В общем, окончательное решение достаточно логичное и простое, но как-то долго я до него шел. Сейчас
кучу кода придется переделывать обратно.

20140808 05:58
Пытаюсь снова "врубиться" в проект. Пожалуй, мой оптимизм по поводу того, что все продумано, оказался преждевременным.
Более или менее складная картинка получается если имеется одна таблица и нет связей с другии элементами. Наличие
связей ее сильно "портит". 

При продумывании, я рассмотрел вариант отказа от множественности коллекций в пользу единого хранилища объектов.
Однако, при таком подходе трудно решать задачу индексации по отдельным полям объектов разных классов. Этот 
путь ведет в RDF и об этом говорил Юрий Платонов. Я про RDF уже много чего знаю, поэтому попробую поработать
с много-табличной объектной моделью. 

Другой момент - динамика построения таблиц. Сейчас можно делать все что угодно: заводить таблицы не одновременно
и вперемешку с заполнением данными, чистить таблицы, видимо даже убивать таблицы. Все это сомнительно. 
Возможным решением является объектное представление в стиле DataSet. При этом, реализация некоторых интерфейсов 
этого класса, открыло бы дорогу для практического применения. Этот "стиль" я вижу в том, что сначала определяется
полная схема данных, наверное включая индекные столбцы, а потом производится "заливка" данными, потом или одновременно
- работа с данными.

С другой стороны, можно попробовать использовать внутренний уровень реализации для того, чтобы сделать стройную 
картинку поддержания объектной модели. Для полей это пока получалось, надо попробовать написать get/set для 
ссылочных полей и обратных полей.

20140809 16:15
Кое-что получилось, но удовлетворения это не принесло. К имеющимся для определяемых классов реализации свойств
полей, добавил реализацию "прямой ссылки". Выглидт это не так чтобы слишком мудрено:
        public City City
        {
            get
            {
                int ccod = (int)entry.Field(2).Field(2).Get();
                Database db = this.inCollection.InDatabase;
                var collec = db.Collection("cities");
                var q = collec.Element(ccod).entry;
                return new City() { entry = q };
            }
        }

Пока не написал "обратное" свойство. Это кода для объекта типа город вычисляется множество (поток) проживающих
в нем персон. Наверное будет что-то похожее. Что меня беспокоит? То, что на Поляровском уровне не задается 
полная схема базы данных. Поэтому получается "ручное" творчество. А если бы задавалась, то можно было бы генерировать 
систему классов через Reflection. Наверное... Или просто генерацией кода. Хорошо бы посмотреть как это делается 
в других системах.

Посмотрел я в документации. Есть аналогичный подход в .NET, называется Entity Data Model (EDM). Не вижу смысла
погружаться в эту не очень простую "кухню", попробую довести до работоспособности свой подход.

Мне нужно поле для экспериментов. Похоже, придется реализовать стародавнюю задумку: сделать вариант данных фотоархива 
в виде реляционных таблиц.

20140810 05:59
Вчера так и не продвинулся... Остановился на том, что нужно делать тест. Но для чего? Какую функциональность я
могу проверить? Какую производительность измерить и с чем сопоставить? 

Сейчас проверил. Есть у меня дистрибутивы и MySql и SqLight, естестенно, есть MS Sql Server. Надо сделать все попроще
и будет с чем сравнивать. Потом можно будет еще сравнить с последней реализацией RDF. Что-ж пожалуй попробую сделать.

Сначала надо сделать преобразователь моего RDF в XML. Найду файл и буду делать.

Файл нашел. Сейчас сделаю чего-нибудь.

С некоторым напрягом, но справился. Получился компактный тест, удовлетворяющий некоторому набору требований. 
Тестовые данные, это еще не все. Нужен поток собственно тестов по вычислениям на этих данных.  
Что можно сделать с помощью данного теста? 

20140811 06:00
Очень немного я за вчера сделал... Сегодня также ожидается суетный день, попробую сделать хотя бы также немного.

Итак, я остановился на планировании. Надо создать план дальнейшей работы. В принципе, можно много чего делать.
Но нужна основа. Основа будет: данные, тест, выполнение тестов на данных. Дальше можно будет думать о генерации данных,
генерации тестов и выполнении новых тестов, в том числе и в новых условиях, на новых решениях.

Да, есть еще одна задача, в которой я не смог определиться. Это выявление типа сущности. В принципе, по построению,
у нас всегда известен тип ссылки. Но ссылки кодируются и пока не различаются. Поэтому, в дальнейшем, будет трудно
определить к какой "таблице" обращаться с конкретным идентификатором. Можно синтиксически тип "встроить" в
идентификатор, напр. добавив первую букву. Можно отдельно тип передавать. Нечто похожее возникает и в поиске
по частичному совпадению со строковым образцом. Там лучше прямо задавать тип (таблицу). Пожалуй, остановлюсь на
задании типа дополнительным параметром. И декларирую метод типа GetItemByCodeIn(int code, string type);

Кое-что сделал. Простейшая реализация дает:
поиск по частичному совпадению имени с образцом - 34-80 мс.
получение айтема по идентификатору - 2 мс. (для двух - 2 мс.)

Результаты сами по себе довольно интересные. Вроде производится сканирование и в том и в другом случае, а времена 
сильно разнятся. Думаю, дело во внутреннем кодировании, примененном в Xml.Linq. Конечно, пока реализация получения 
айтема по идентификатору не та, которая нужна. Нужна реализация с прохождением двух уровней: person - reflection - photo-doc

Теперь надо написать генератор тестов.      
 
Предыдущая форма теста меня более или менее удовлетворяла. Правда только в части изменений производительности и частичной
проверки функциональности (по количеству результатов). Воспроизведу эту систему, только добавлю тип для портрета.
Кроме того, в режиме вывода-накопления, эти строки добавляются к файлу, а в режиме чтения/использования, они помещаются
под элемент tests

<tests>
	<search db="dbname" dbms="dbmsname" duration="2" ss="Марчук" res="14"/>
	<portrait db="dbname" dbms="dbmsname" duration="2" id="222" type="person" res="14"/>

</tests>

Буду "кидать" случайные индексы и проверять. Есть индекс "попал" в системный объект, то генерируется строка. Причем, 
с некоторой вероятностью генерируется поисковый запрос.

"Ползком", но продвигаюсь. Создал данные, сгенерировал тест, написал простую программу исполнения теста для xml-движка.
В общем, кое-сто работает. Теперь надо попробовать "затолкать" данные в объектное представление и написать пропуск
теста. Посмотрю "масштабы бедствия".

Действительно, не все так просто... Напрямую решения из PObjectives плохо "ложатся" на задачу. В частности,
ключевой идентификатор id и ссылки по ref, плохо гармонируют со встроенным идентификатором. Попробую задачу
решить применением старой технологии TableWithIndex. Перейду в другой проект.

20140812 14:32
Вчера неплохо поработал, хотя и не написал про то. А еще лучше - ночью, когда не спалось. Написал реализацию 
трех-табличной базы данных и добился, чтобы поиск по образцу заработал. Сейчас попробую сделать выдачу портрета,
причем - как надо.

20140817 16:30
Слишком давно я не занимался этим проектом. Возможно, меня обескуражили не очень хорошие результаты по производительности.
Правда сравнивать не с чем, может эти результаты о-го-го!

Вернуться к проекту меня сподвигнула ИДЕЯ (!). Идея заключается в том, чтобы распространить на таблично-объектные 
построения последнюю схему, которую я разрабатывал для RDF. Схема заключается в том, что выстраивается новая таблица,
причем в виде ячейки фиксированного формата. У новой таблицы есть "старые" поля, но также есть новые. Эти новые, 
соответствуют обратным отношениям и представлют собой последовательности кодов в чужой таблице, ссылающейся на
данную. Получается, что есть набор пар: таблица-коды, коды строчек, в которых для этой таблицы есть external key,
ссылающийся на данную запись. Должно получиться...

Посмотрю как этот подход вписывается в контекст предложенного объектного построения.

20140818 03:43
Смотрел, смотрел, ничего не высмотрел... Даже в Википедию сходил, посмотрел всякие там object-relational mapping,
Hibernate и др. Четкой картины пока не появилось. Надо продолжать обдумывать. Пока не спалось, думал. Придумал
следующее. Оптимизирующее "длинное" представление следует порождать в том момент, когда программа вышла на
данную запись. При редактированиях - добавлению, уничтожению и замене, надо с этой записью что-то делать в кеше,
а также надо убрать из кеша (кешей) те записи, на которые данная ссылается. 
Появилась идея для спецификации объектного представления использовать форматы. Тогда, по крайней мере, позиция
полей (столбцов) будет определена. Пусть используется формат:
<record type="имя таблицы">
  <field prop="имя столбца/свойство" type="тип столбца" />
  ...
  <direct prop="имя столбца/свойство" type="тип (имя) внешней таблицы" />
  ...
</record>

Вроде получается. Но имена обратных столбцов и их позиции, не намечены. Допустим, мы разрешаем обратные отношения.
Позиция столбца определена, имя столбца или свойство также определено, а вот типа (имени) таблицы не достаточно.
Ведь таблица может ссылаться на данную несколькими столбцами (как, напр. в RDF).

Итак, добавляю в запись обратное отношение:
  <inverse prop="имя столбца/свойство" type="тип (имя) внешней таблицы" fromprop="имя столбца/свойство" />
  
Теперь можно попробовать написать программу. Какую именно? Программу, которая по спецификации базы данных, 
сконструирует ее из ячеек. А потом проинтерпретирует нужные действия в виде програм типа SearchByNameIn и 
GetPortraitByIdIn. 

Вообще-то я еще не убедился в эффективности такой среды обработки, но судя по успехам PolarBasedRDF, работать подход
должен хорошо.

20140819 02:49
Вчера, в рамках "убеждания в эффективности...", расширил дерево результата для получения портрета. В разогнанном 
состоянии, на "моем" портрете, время его формирования, получается 26 мс. Это для получения графа, с количеством дуг в
660. Много это или мало? Попробую подсчитать. Сначала ищется количество ключевых чтений с диска.       
В базе данных - 10 тыс. персон, 20 тыс. фотографий, 60 тыс. отражений. Соответственно, для доступа к персоне тебуется
удвоенный логарифм 2*14 = 28 плюс еще парочка, итого - 30 чтений. Далее, идет 110 отражений. Это:
110 * (16 + 2 * 15) = 5060, всего 5090 запросов. ЧТо-то много получается... При скорости доступа к файлу в 100-120 тыс.
запросов в сек., результат должен быть 40-50 мс. А он меньше... Наверное, работает еще какая-то оптимизация. Хотя
измерения на TotalTest этого не подтверждают. Возможно, данный результат является вполне приличным, что и требовалось
доказать...

Теперь посоображаю что я буду делать с объектной реализацией, которую я замыслил. Наверное, ее надо проверять на тех
же данных и тестах. 

Первичная генерация вроде работает, правда проверить не на чем. Я вот на чем застрял. Я, в стиле объектных построений, 
завел скрытый ключ. Правда он строится пока не правильно (определение keyNew не учитывает (возможных) процессов уничтожения.
Так вот это скрытый ключ непонятно как должен взаимодействовать с явным ключем. Почти в любой системе изложения графа,
нам требуется явное указание на связи одного с другим и это делается с помощью явного ключа или идентификатора. В принципе,
я к этому и вел, но для целей порождения новых элементов коллекции, потребовался генератор новых ключей. Я сделал какой-то,
но как-то это не выглядит правильным. Предположим, мы получаем ключи извне. Это логично в силу того, что может одновременно 
с объектной существовать и другая форма представления графа. Тогда, для порождения новых объектов, мы должны или кого-то
запрашивать на предмет получения нового ключа, либо получать уже снабженную ключем запись. Второй способ выглядит знакомее.

В принципе, такой подход выглядит приемлемым. Меняется только коллекционный метод CreateElement на
public Element CreateElement(int key, object pvalue)

Кстати, надо систематически поменять id на key. Вопрос заключается в том, как реализовывать явное порождение нового
элемента. Надо сделать похожим образом:
TElement elememnt = new TElement();  
но это не годится, должно быть что-то вроде:
TElement element = collection.CreateElement();  

Наверное, в коллекцию надо передавать еще и генератор нового идентификатора, точнее, ключа. 

Сейчас несколько запутался в том, как должны быть структурированы классы Database, Collection, класс, использующий их для 
создания конкретной базы данных. Я пока отвергаю варианты слишком гибкого построения базы данных. База данных должна 
состоять из фиксированного вначале числа и типов коллекций, структуры этих коллекций. У меня имеется два этапа формирования
базы данных. Первый - построение нужных таблиц (коллекций). Второй - заполнение базы данных данными. Второй этап может 
выполняться многократно. Это - перезагрузка данных в имеющуюся структуру. Причем база данных обнуляется в части содержимого,
но остается прежней в части структуры (это как ячейка, только более высокого уровня). Значит, должна быть команда Clear(), 
применимая ко всей базе данных. Соответственно, команда Load(XElement xdb). В принципе, загрузка базы данных, определяется
структурой и договоренностью по XML-структуре файла базы данных. Или файлов базы данных, но этого пока реализовывать не 
будем. Главное то, что загрузка должна быть определена где-то на том же или более высоком слое, что и констуирование.

20140820 01:58
Опять не спится. Похоже, что ночь и раннее утро - единственная возможность поработать. Попробую ее использовать. 

Надо бы подправить ProgramInterpretator.

Опять пришлось работать ночью. С 2-х до 4-х сделал довольно много. Главное - "заставил" работать ввод данных. Теперь
займусь перекресной индексацией и визуализацией.

Частичный портрет (только запись) уже начал получаться. Данные по изменению скорости несоклько противоречивы, но есть
результаты до полумиллисекунды на один портрет. Поскольку там где-то 13 обращений к памяти, то результаты соответствуют
"законам сохранения". 

Теперь надо "напрячься" и сделать полный портрет, управляемый форматом. В качестве прототипа, возьму то, что
было запрограммировано в ProgramTableEngine.

Для конкретного типа, напр. person, в формате должен быть указан обратный "путь". То есть, имя обратного отношения,
потом поля и др. для получившейся записи. Это я смогу сделать легко. А что дальше? Дальше мы возвращаемся к описанию
схемы и к созданию дополнительных индексов. 

20140821 02:59
Сегодня День рождения Наташи! Правда у них пока еще 20-е, вечерком надо будет позвонить.

Я застрял на том, как отмечать то, что есть колонки с прямыми ссылками. А главное, как формировать индексы по этим
колонкам и как их использовать. Ответ на первый вопрос пока не исчерпал себя - это в схеме данных. Есть таблица, 
есть колонки, есть указание что колонка "direct". Есть имя колонки, которое в совокупности с именем таблицы, 
представляется уникальным. По схеме, все довольно просто может быть выявлено. Создадим синтетическое имя:
имя-таблицы$имя-колонки
Это имя будем использовать для индексов. Надо будет найти место для генерации индексов и поддержания при изменениях.

Но сначала, хочется понять как индексами пользоваться? 

В общем, гляжу на код и не очень понимаю как его приводить к нужному варианту надо... Проблема видится в том,
что пока сопровождение индексов оставлено на ручные действия. Типа того, что изменили опорную последовательность
(путем добавления записи?) и потом надо "вручную" добавить этот вход к индексам. А их может быть несколько...
Аналогично, при подключении к базе данных. Подключились к ячейке с опорной таблицей, потом вручную, подключаемся к 
индексам. Предположим, мы хотим выполнять подобные действия автоматически. У на опорные таблицы находятся в 
спецификаторе базы данных. Этот спецификатор пока располагается в ячейке catalogue.pac. Но я убедился, что нам нужна 
схема. В схеме, прямо или косвенно имеется та же инфрмация. Схема - это тот же файл. Только не будет потенциальной
проблемы с сохранением типов ячеек. 

Итак, попробую умозрительно пройтись по формируемому решению. 
1. Есть файл схемы, в тем в XML-формате и специфической форме, изложена схема базы данных: набор таблиц, структура
таблиц, внешние ключи, индексные колонки, способы индексации и др.
2. По этому файлу производится подключение к базе данных или ее генерация. Собственно база данных формируется
в терминах таблиц и индексов (сейчас я использую FlexIndex). Соответственно, мы управляем не только созданием базы 
данных, но и ее наполнением и модификацией. 

В общем, склоняюсь к минимальным изменениям в существующем недо-решении. Главное - добавление индексов на столбцы 
External key. В названии индекса, на всякий случай, имеется и тип "откуда" и идентификатор "стрелки" (столбца) и 
тип "куда". Но это - на всякий случай. Главное - прямое управление синхронизацией таблиц с индексами. Что это
означает? Для каждой таблицы, нужно запустить загрузку ее индексов. Собственно, в объектах индексов находится 
нужная привязка к базовой таблице. А в случае "маленького" изменения, нужно для всех них делать AppendEntry.

Вновь плохо получается... Проблема выявлена в том, что индекс - это не коллекция. А Catalogue поддерживает только
коллекции. Возможно, от структуры catalogue придется отказаться.   

20140823 04:03
Вчера, хоть и не писал, но сделал много. Главное - заработала программа и выдает правильные результаты. Пока нет
поиска по текстовому образцу. Это потому что нет концепции формирования и использования других индексов, по
сравнению с внешними ссылками. Немножко беспокоит время построения информационного портрета. На "мне", получается
около 100 мс. Вроде немного, но и немало.  
 
Сообразил, что засекан ие времени я поставил за выводом, а от может влиять на чистое время. Изменил, и точно - 
35 мс. Очень хорошее время! Можно позавтракать, полечиться и т.д.

Эти результаты можно улучшать. Простым улучшением будет добавление кеша (словаря) объектов к таблицам (коллекциям).
Более сложным будет формирование "длинной" записи для объектов и ее сохранение в кеше.

20140924 11:58
Пытаюсь оценить достигнутый результат. Сделал простое SQL-решение. Правда что-то напутал со сравнением строк по LIKE,
но в целом работает. В принципе, результаты тестирования SQL-решения более или менее укладываются в базовые представления
о скоростях чтения с диска. Вот, например, сечас произвел пропуск тестов после перезагрузки компьюетра. Простой Count 
выполняется 12 сек. Доступ к отдельной записи типа "person" - 320 мс., тест пропуска Tracer - 7 сек.

Появилось ощущение, что MS SQL Server не использует системные кеши при доступе к файлам. Это из-за того, что я 
перезагружаю компьютер, потом файл базы данных копирую в какое-то место (это для того, чтобы его "потрогать"), а
потом исполняю тест. Результат качественно неизменен. В частности, 16 сек. на вычисление Count выглядит великоватым.
Правда все Tracer-тесты выполнились за 5 сек. Но было и 10. 

Повторный пропуск теста, дает по Count'у 445 мс., единичная запись извлекается за 7 мс., единичное отношение создается за
388 мс., все Tracer-тесты - 4.7 сек. Еще раз:  
521, 6, 379, 4238

Тестирую программу ProgramDatabase.
После перезагрузки, отдельный портрет вычислялся 1686 мс. Все tracer-тесты выполнились за 4282 мс. 
После посторного запуска, tracer-тесты выполнились за 128 мс.
После новой перезагрузки и "трогания данных", результат сразу становиться в категорию 2 - 139 мс., одиночный портрет 84 мс.
Выход "на стационар" для трассерного теста, это приблизительно такой и есть - 140-145 мс. Повторное исполнение теста
сразу за первым дает 59 мс.

Вернувшись к SQL, снова получаю: 7 сек., при повторах 4485, 3933, 4201
Похоже, в 30 раз медленнее!



 





 
 


   


 

 
 

    

 


 
 
